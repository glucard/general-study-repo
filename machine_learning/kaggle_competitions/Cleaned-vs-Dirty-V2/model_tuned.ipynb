{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_path = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_learning_model(classifier_dropout):\n",
    "    model_weights = models.VGG19_Weights.DEFAULT\n",
    "    model_ft = models.vgg19(weights=model_weights)\n",
    "\n",
    "    for param in model_ft.parameters():\n",
    "        # param.requires_grad = False\n",
    "        param.requires_grad = True\n",
    "\n",
    "    for param in model_ft.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    model_ft.classifier[-1] = nn.Linear(model_ft.classifier[-1].in_features, 2)\n",
    "\n",
    "    for layer in model_ft.classifier:\n",
    "        if isinstance(layer, nn.Dropout):\n",
    "            layer.p = classifier_dropout\n",
    "    \n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cleaned', 'dirty'], device(type='cuda', index=0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.utils\n",
    "\n",
    "target_transforms = transforms.Compose([\n",
    "    lambda x:torch.tensor(x), # or just torch.tensor\n",
    "    lambda x:F.one_hot(x,2)\n",
    "])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(0, 360)),\n",
    "        transforms.RandomResizedCrop(256, scale=(0.5, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=(0.3, 1)),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(0, 360)),\n",
    "        transforms.RandomResizedCrop(256, scale=(0.8, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=(0.3, 1)),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = os.path.join(curr_path, \"data\")\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x], target_transform=target_transforms)\n",
    "                  for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# image_datasets['train'], image_datasets['val'] = torch.utils.data.random_split(image_datasets['train'], [30, 10])\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=50,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, optimizer, clip_value):\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(dataloaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target.float())\n",
    "\n",
    "        total += output.size(0)\n",
    "        running_loss += loss.item() * output.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        _, correct_class = torch.max(target.data, 1)\n",
    "        \n",
    "        correct += (predicted == correct_class).sum().item()\n",
    "    \n",
    "    return {\n",
    "        \"mean_loss\": running_loss / total,\n",
    "        \"mean_accuracy\": correct / total,\n",
    "    }\n",
    "\n",
    "def test_func(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(dataloaders['val']):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "\n",
    "            # accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, correct_class = torch.max(target.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == correct_class).sum().item()\n",
    "\n",
    "            # loss\n",
    "            running_loss += F.cross_entropy(outputs, target.float()).item() * outputs.size(0)\n",
    "    \n",
    "    return {\n",
    "        \"mean_loss\": running_loss / total,\n",
    "        \"mean_accuracy\": correct / total,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "def train_dishs(config, max_epochs=20, tunning=True):\n",
    "    # Data Setup\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = get_transfer_learning_model(config['classifier_dropout'])\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config['weight_decay'])\n",
    "    for i in range(max_epochs):\n",
    "        train_log = train_func(model, optimizer, config['clip_value'])\n",
    "        val_log = test_func(model)\n",
    "\n",
    "        if tunning:\n",
    "            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "                checkpoint = None\n",
    "                if (i + 1) % max_epochs == 0 and (val_log[\"mean_loss\"] < 0.4):\n",
    "                    # This saves the model to the trial directory\n",
    "                    torch.save(\n",
    "                        model.state_dict(),\n",
    "                        os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
    "                    )\n",
    "                    checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "                # Send the current training result back to Tune\n",
    "                train.report(\n",
    "                    {\n",
    "                        \"train_mean_loss\": train_log[\"mean_loss\"],\n",
    "                        \"train_mean_accuracy\": train_log[\"mean_accuracy\"],\n",
    "                        \"val_mean_loss\": val_log[\"mean_loss\"],\n",
    "                        \"val_mean_accuracy\": val_log[\"mean_accuracy\"],\n",
    "                    },\n",
    "                    checkpoint=checkpoint\n",
    "                )\n",
    "        else:\n",
    "            print(\"-\"*10, f\"epoch: {i+1}/{max_epochs}\",\"-\"*10)\n",
    "            print(f\"train: {train_log}\\nval: {val_log}\")\n",
    "    if not tunning:\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"log\": {\n",
    "                \"train\": train_log,\n",
    "                \"val\": val_log,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config = {\\n    \"lr\":0.1,\\n    \"momentum\":0.5,\\n}\\n\\ntrain_dishs(config)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"config = {\n",
    "    \"lr\":0.1,\n",
    "    \"momentum\":0.5,\n",
    "}\n",
    "\n",
    "train_dishs(config)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-15 14:57:06</td></tr>\n",
       "<tr><td>Running for: </td><td>00:13:48.00        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.5/15.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  classifier_dropout</th><th style=\"text-align: right;\">  clip_value</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_mean_loss</th><th style=\"text-align: right;\">  train_mean_accuracy</th><th style=\"text-align: right;\">  val_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dishs_ae947690</td><td>TERMINATED</td><td>172.18.58.174:539858</td><td style=\"text-align: right;\">            0.83629 </td><td style=\"text-align: right;\">    2.72739 </td><td style=\"text-align: right;\">0.000867158</td><td style=\"text-align: right;\">  0.659954</td><td style=\"text-align: right;\">    0.00325113</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.0117</td><td style=\"text-align: right;\">         0.899619</td><td style=\"text-align: right;\">             0.6     </td><td style=\"text-align: right;\">       0.702159</td></tr>\n",
       "<tr><td>train_dishs_3734e601</td><td>TERMINATED</td><td>172.18.58.174:542905</td><td style=\"text-align: right;\">            0.547895</td><td style=\"text-align: right;\">    4.50671 </td><td style=\"text-align: right;\">5.99513e-05</td><td style=\"text-align: right;\">  0.570225</td><td style=\"text-align: right;\">    0.0125885 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.6431</td><td style=\"text-align: right;\">         0.823211</td><td style=\"text-align: right;\">             0.366667</td><td style=\"text-align: right;\">       0.639833</td></tr>\n",
       "<tr><td>train_dishs_35efa26e</td><td>TERMINATED</td><td>172.18.58.174:545906</td><td style=\"text-align: right;\">            0.585355</td><td style=\"text-align: right;\">    2.24106 </td><td style=\"text-align: right;\">0.0425951  </td><td style=\"text-align: right;\">  0.708724</td><td style=\"text-align: right;\">    0.0405391 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.7357</td><td style=\"text-align: right;\">         0.445558</td><td style=\"text-align: right;\">             0.733333</td><td style=\"text-align: right;\">       0.393643</td></tr>\n",
       "<tr><td>train_dishs_d563830e</td><td>TERMINATED</td><td>172.18.58.174:548916</td><td style=\"text-align: right;\">            0.815419</td><td style=\"text-align: right;\">    4.03424 </td><td style=\"text-align: right;\">0.366466   </td><td style=\"text-align: right;\">  0.826378</td><td style=\"text-align: right;\">    0.0118158 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9736</td><td style=\"text-align: right;\">        24.666   </td><td style=\"text-align: right;\">             0.433333</td><td style=\"text-align: right;\">       2.08141 </td></tr>\n",
       "<tr><td>train_dishs_ef736066</td><td>TERMINATED</td><td>172.18.58.174:551921</td><td style=\"text-align: right;\">            0.511643</td><td style=\"text-align: right;\">    1.08207 </td><td style=\"text-align: right;\">0.000490123</td><td style=\"text-align: right;\">  0.69297 </td><td style=\"text-align: right;\">    0.125463  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9238</td><td style=\"text-align: right;\">         0.824623</td><td style=\"text-align: right;\">             0.266667</td><td style=\"text-align: right;\">       0.694361</td></tr>\n",
       "<tr><td>train_dishs_30778226</td><td>TERMINATED</td><td>172.18.58.174:554934</td><td style=\"text-align: right;\">            0.682281</td><td style=\"text-align: right;\">    4.07201 </td><td style=\"text-align: right;\">0.00214614 </td><td style=\"text-align: right;\">  0.652695</td><td style=\"text-align: right;\">    0.101587  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9214</td><td style=\"text-align: right;\">         0.687459</td><td style=\"text-align: right;\">             0.6     </td><td style=\"text-align: right;\">       0.745214</td></tr>\n",
       "<tr><td>train_dishs_7d09c6a7</td><td>TERMINATED</td><td>172.18.58.174:557939</td><td style=\"text-align: right;\">            0.680769</td><td style=\"text-align: right;\">    1.67005 </td><td style=\"text-align: right;\">0.00867453 </td><td style=\"text-align: right;\">  0.288225</td><td style=\"text-align: right;\">    0.00263019</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.8913</td><td style=\"text-align: right;\">         0.607087</td><td style=\"text-align: right;\">             0.533333</td><td style=\"text-align: right;\">       0.660941</td></tr>\n",
       "<tr><td>train_dishs_049d37ef</td><td>TERMINATED</td><td>172.18.58.174:560934</td><td style=\"text-align: right;\">            0.729702</td><td style=\"text-align: right;\">    1.09928 </td><td style=\"text-align: right;\">0.172575   </td><td style=\"text-align: right;\">  0.580567</td><td style=\"text-align: right;\">    0.00617589</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.0093</td><td style=\"text-align: right;\">         0.577945</td><td style=\"text-align: right;\">             0.766667</td><td style=\"text-align: right;\">       0.472404</td></tr>\n",
       "<tr><td>train_dishs_f86f883b</td><td>TERMINATED</td><td>172.18.58.174:563939</td><td style=\"text-align: right;\">            0.814589</td><td style=\"text-align: right;\">    3.05409 </td><td style=\"text-align: right;\">0.000933882</td><td style=\"text-align: right;\">  0.536193</td><td style=\"text-align: right;\">    0.0327097 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1624</td><td style=\"text-align: right;\">         0.756033</td><td style=\"text-align: right;\">             0.566667</td><td style=\"text-align: right;\">       0.678921</td></tr>\n",
       "<tr><td>train_dishs_7df621a5</td><td>TERMINATED</td><td>172.18.58.174:566944</td><td style=\"text-align: right;\">            0.697718</td><td style=\"text-align: right;\">    3.78301 </td><td style=\"text-align: right;\">0.00274594 </td><td style=\"text-align: right;\">  0.472526</td><td style=\"text-align: right;\">    0.0132951 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.8807</td><td style=\"text-align: right;\">         0.528733</td><td style=\"text-align: right;\">             0.666667</td><td style=\"text-align: right;\">       0.655869</td></tr>\n",
       "<tr><td>train_dishs_02edc430</td><td>TERMINATED</td><td>172.18.58.174:569945</td><td style=\"text-align: right;\">            0.621027</td><td style=\"text-align: right;\">    0.851016</td><td style=\"text-align: right;\">0.000171011</td><td style=\"text-align: right;\">  0.517879</td><td style=\"text-align: right;\">    0.00340072</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1518</td><td style=\"text-align: right;\">         0.631969</td><td style=\"text-align: right;\">             0.7     </td><td style=\"text-align: right;\">       0.639778</td></tr>\n",
       "<tr><td>train_dishs_fcd2a2f1</td><td>TERMINATED</td><td>172.18.58.174:572949</td><td style=\"text-align: right;\">            0.637565</td><td style=\"text-align: right;\">    4.85909 </td><td style=\"text-align: right;\">0.0731169  </td><td style=\"text-align: right;\">  0.431382</td><td style=\"text-align: right;\">    0.119264  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.3183</td><td style=\"text-align: right;\">         0.687422</td><td style=\"text-align: right;\">             0.666667</td><td style=\"text-align: right;\">       0.707849</td></tr>\n",
       "<tr><td>train_dishs_0f0d6499</td><td>TERMINATED</td><td>172.18.58.174:575966</td><td style=\"text-align: right;\">            0.740663</td><td style=\"text-align: right;\">    1.91324 </td><td style=\"text-align: right;\">0.0878326  </td><td style=\"text-align: right;\">  0.874816</td><td style=\"text-align: right;\">    0.00369232</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.2055</td><td style=\"text-align: right;\">         0.668358</td><td style=\"text-align: right;\">             0.566667</td><td style=\"text-align: right;\">       0.721539</td></tr>\n",
       "<tr><td>train_dishs_04ed06e0</td><td>TERMINATED</td><td>172.18.58.174:578971</td><td style=\"text-align: right;\">            0.898952</td><td style=\"text-align: right;\">    4.2373  </td><td style=\"text-align: right;\">0.000281973</td><td style=\"text-align: right;\">  0.690482</td><td style=\"text-align: right;\">    0.00511842</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.3188</td><td style=\"text-align: right;\">         0.851976</td><td style=\"text-align: right;\">             0.666667</td><td style=\"text-align: right;\">       0.750703</td></tr>\n",
       "<tr><td>train_dishs_15673b27</td><td>TERMINATED</td><td>172.18.58.174:581989</td><td style=\"text-align: right;\">            0.7781  </td><td style=\"text-align: right;\">    1.0681  </td><td style=\"text-align: right;\">5.30318e-05</td><td style=\"text-align: right;\">  0.132189</td><td style=\"text-align: right;\">    0.024525  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.4717</td><td style=\"text-align: right;\">         1.0509  </td><td style=\"text-align: right;\">             0.466667</td><td style=\"text-align: right;\">       0.72216 </td></tr>\n",
       "<tr><td>train_dishs_37184ebd</td><td>TERMINATED</td><td>172.18.58.174:584995</td><td style=\"text-align: right;\">            0.601255</td><td style=\"text-align: right;\">    0.363117</td><td style=\"text-align: right;\">0.000816189</td><td style=\"text-align: right;\">  0.741708</td><td style=\"text-align: right;\">    0.0027033 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.5229</td><td style=\"text-align: right;\">         0.79858 </td><td style=\"text-align: right;\">             0.533333</td><td style=\"text-align: right;\">       0.702737</td></tr>\n",
       "<tr><td>train_dishs_c33e6361</td><td>TERMINATED</td><td>172.18.58.174:588000</td><td style=\"text-align: right;\">            0.601923</td><td style=\"text-align: right;\">    3.98378 </td><td style=\"text-align: right;\">6.36855e-05</td><td style=\"text-align: right;\">  0.262574</td><td style=\"text-align: right;\">    0.00254018</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.0939</td><td style=\"text-align: right;\">         0.794855</td><td style=\"text-align: right;\">             0.4     </td><td style=\"text-align: right;\">       0.775424</td></tr>\n",
       "<tr><td>train_dishs_96b1d62b</td><td>TERMINATED</td><td>172.18.58.174:591005</td><td style=\"text-align: right;\">            0.827864</td><td style=\"text-align: right;\">    1.33337 </td><td style=\"text-align: right;\">0.0880433  </td><td style=\"text-align: right;\">  0.311445</td><td style=\"text-align: right;\">    0.00453684</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.2012</td><td style=\"text-align: right;\">         0.724445</td><td style=\"text-align: right;\">             0.666667</td><td style=\"text-align: right;\">       0.556217</td></tr>\n",
       "<tr><td>train_dishs_b40fa844</td><td>TERMINATED</td><td>172.18.58.174:594010</td><td style=\"text-align: right;\">            0.781298</td><td style=\"text-align: right;\">    0.553963</td><td style=\"text-align: right;\">0.00364307 </td><td style=\"text-align: right;\">  0.786114</td><td style=\"text-align: right;\">    0.00270895</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9603</td><td style=\"text-align: right;\">         0.857093</td><td style=\"text-align: right;\">             0.433333</td><td style=\"text-align: right;\">       0.685298</td></tr>\n",
       "<tr><td>train_dishs_0b70ea5a</td><td>TERMINATED</td><td>172.18.58.174:597014</td><td style=\"text-align: right;\">            0.526148</td><td style=\"text-align: right;\">    0.453333</td><td style=\"text-align: right;\">4.8085e-05 </td><td style=\"text-align: right;\">  0.346445</td><td style=\"text-align: right;\">    0.0176771 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.2838</td><td style=\"text-align: right;\">         0.763123</td><td style=\"text-align: right;\">             0.5     </td><td style=\"text-align: right;\">       0.811436</td></tr>\n",
       "<tr><td>train_dishs_048a4f4a</td><td>TERMINATED</td><td>172.18.58.174:600019</td><td style=\"text-align: right;\">            0.544507</td><td style=\"text-align: right;\">    3.26122 </td><td style=\"text-align: right;\">0.0167042  </td><td style=\"text-align: right;\">  0.600012</td><td style=\"text-align: right;\">    0.0491852 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.6857</td><td style=\"text-align: right;\">         0.494762</td><td style=\"text-align: right;\">             0.866667</td><td style=\"text-align: right;\">       0.253179</td></tr>\n",
       "<tr><td>train_dishs_beef41ed</td><td>TERMINATED</td><td>172.18.58.174:603026</td><td style=\"text-align: right;\">            0.56715 </td><td style=\"text-align: right;\">    2.26763 </td><td style=\"text-align: right;\">0.0237139  </td><td style=\"text-align: right;\">  0.87572 </td><td style=\"text-align: right;\">    0.0641124 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.6508</td><td style=\"text-align: right;\">         0.554662</td><td style=\"text-align: right;\">             0.733333</td><td style=\"text-align: right;\">       0.394204</td></tr>\n",
       "<tr><td>train_dishs_98e5367b</td><td>TERMINATED</td><td>172.18.58.174:606037</td><td style=\"text-align: right;\">            0.566974</td><td style=\"text-align: right;\">    4.9512  </td><td style=\"text-align: right;\">0.0303039  </td><td style=\"text-align: right;\">  0.445912</td><td style=\"text-align: right;\">    0.00773283</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.986 </td><td style=\"text-align: right;\">         0.463315</td><td style=\"text-align: right;\">             0.733333</td><td style=\"text-align: right;\">       0.501007</td></tr>\n",
       "<tr><td>train_dishs_3be585c7</td><td>TERMINATED</td><td>172.18.58.174:609050</td><td style=\"text-align: right;\">            0.638011</td><td style=\"text-align: right;\">    2.26591 </td><td style=\"text-align: right;\">0.0080564  </td><td style=\"text-align: right;\">  0.768144</td><td style=\"text-align: right;\">    0.0378342 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9809</td><td style=\"text-align: right;\">         0.36886 </td><td style=\"text-align: right;\">             0.866667</td><td style=\"text-align: right;\">       0.536371</td></tr>\n",
       "<tr><td>train_dishs_d461e076</td><td>TERMINATED</td><td>172.18.58.174:612055</td><td style=\"text-align: right;\">            0.566087</td><td style=\"text-align: right;\">    3.35839 </td><td style=\"text-align: right;\">0.000128793</td><td style=\"text-align: right;\">  0.393984</td><td style=\"text-align: right;\">    0.00923352</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9504</td><td style=\"text-align: right;\">         0.765173</td><td style=\"text-align: right;\">             0.5     </td><td style=\"text-align: right;\">       0.71906 </td></tr>\n",
       "<tr><td>train_dishs_cb5e58d0</td><td>TERMINATED</td><td>172.18.58.174:615060</td><td style=\"text-align: right;\">            0.502218</td><td style=\"text-align: right;\">    4.53694 </td><td style=\"text-align: right;\">0.0467779  </td><td style=\"text-align: right;\">  0.56508 </td><td style=\"text-align: right;\">    0.0715279 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9151</td><td style=\"text-align: right;\">         0.338575</td><td style=\"text-align: right;\">             0.866667</td><td style=\"text-align: right;\">       1.00725 </td></tr>\n",
       "<tr><td>train_dishs_20feda8f</td><td>TERMINATED</td><td>172.18.58.174:618055</td><td style=\"text-align: right;\">            0.504767</td><td style=\"text-align: right;\">    2.6214  </td><td style=\"text-align: right;\">0.323727   </td><td style=\"text-align: right;\">  0.615403</td><td style=\"text-align: right;\">    0.0205951 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9216</td><td style=\"text-align: right;\">         5.53185 </td><td style=\"text-align: right;\">             0.5     </td><td style=\"text-align: right;\">       0.681624</td></tr>\n",
       "<tr><td>train_dishs_62711217</td><td>TERMINATED</td><td>172.18.58.174:621055</td><td style=\"text-align: right;\">            0.537345</td><td style=\"text-align: right;\">    3.50212 </td><td style=\"text-align: right;\">0.0116956  </td><td style=\"text-align: right;\">  0.196802</td><td style=\"text-align: right;\">    0.0609953 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.8812</td><td style=\"text-align: right;\">         0.499402</td><td style=\"text-align: right;\">             0.7     </td><td style=\"text-align: right;\">       0.610998</td></tr>\n",
       "<tr><td>train_dishs_9c329330</td><td>TERMINATED</td><td>172.18.58.174:624050</td><td style=\"text-align: right;\">            0.874825</td><td style=\"text-align: right;\">    2.71452 </td><td style=\"text-align: right;\">0.194386   </td><td style=\"text-align: right;\">  0.653578</td><td style=\"text-align: right;\">    0.0293211 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.8221</td><td style=\"text-align: right;\">         0.782367</td><td style=\"text-align: right;\">             0.4     </td><td style=\"text-align: right;\">       0.733312</td></tr>\n",
       "<tr><td>train_dishs_fff55f8b</td><td>TERMINATED</td><td>172.18.58.174:627052</td><td style=\"text-align: right;\">            0.656092</td><td style=\"text-align: right;\">    2.94323 </td><td style=\"text-align: right;\">0.00131643 </td><td style=\"text-align: right;\">  0.712195</td><td style=\"text-align: right;\">    0.0120627 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1552</td><td style=\"text-align: right;\">         0.674645</td><td style=\"text-align: right;\">             0.6     </td><td style=\"text-align: right;\">       0.81115 </td></tr>\n",
       "<tr><td>train_dishs_1f76a273</td><td>TERMINATED</td><td>172.18.58.174:630057</td><td style=\"text-align: right;\">            0.593894</td><td style=\"text-align: right;\">    1.7278  </td><td style=\"text-align: right;\">0.00634927 </td><td style=\"text-align: right;\">  0.823471</td><td style=\"text-align: right;\">    0.017659  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.8746</td><td style=\"text-align: right;\">         0.514464</td><td style=\"text-align: right;\">             0.7     </td><td style=\"text-align: right;\">       0.849007</td></tr>\n",
       "<tr><td>train_dishs_051f47df</td><td>TERMINATED</td><td>172.18.58.174:633067</td><td style=\"text-align: right;\">            0.948522</td><td style=\"text-align: right;\">    2.31829 </td><td style=\"text-align: right;\">0.0371764  </td><td style=\"text-align: right;\">  0.491906</td><td style=\"text-align: right;\">    0.0467741 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9763</td><td style=\"text-align: right;\">         0.703559</td><td style=\"text-align: right;\">             0.7     </td><td style=\"text-align: right;\">       0.714028</td></tr>\n",
       "<tr><td>train_dishs_db5c0b61</td><td>TERMINATED</td><td>172.18.58.174:636076</td><td style=\"text-align: right;\">            0.664471</td><td style=\"text-align: right;\">    3.69654 </td><td style=\"text-align: right;\">0.000395215</td><td style=\"text-align: right;\">  0.835256</td><td style=\"text-align: right;\">    0.0895786 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9036</td><td style=\"text-align: right;\">         0.684366</td><td style=\"text-align: right;\">             0.6     </td><td style=\"text-align: right;\">       0.825785</td></tr>\n",
       "<tr><td>train_dishs_5b0e8008</td><td>TERMINATED</td><td>172.18.58.174:639070</td><td style=\"text-align: right;\">            0.57718 </td><td style=\"text-align: right;\">    4.52802 </td><td style=\"text-align: right;\">0.00530945 </td><td style=\"text-align: right;\">  0.629938</td><td style=\"text-align: right;\">    0.0146835 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9352</td><td style=\"text-align: right;\">         0.338126</td><td style=\"text-align: right;\">             0.8     </td><td style=\"text-align: right;\">       0.460107</td></tr>\n",
       "<tr><td>train_dishs_f10af201</td><td>TERMINATED</td><td>172.18.58.174:642076</td><td style=\"text-align: right;\">            0.717392</td><td style=\"text-align: right;\">    1.97224 </td><td style=\"text-align: right;\">0.00174045 </td><td style=\"text-align: right;\">  0.389294</td><td style=\"text-align: right;\">    0.00872186</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.8174</td><td style=\"text-align: right;\">         0.637712</td><td style=\"text-align: right;\">             0.633333</td><td style=\"text-align: right;\">       0.666173</td></tr>\n",
       "<tr><td>train_dishs_05aceac8</td><td>TERMINATED</td><td>172.18.58.174:645077</td><td style=\"text-align: right;\">            0.543757</td><td style=\"text-align: right;\">    3.27301 </td><td style=\"text-align: right;\">0.0159451  </td><td style=\"text-align: right;\">  0.584155</td><td style=\"text-align: right;\">    0.0253278 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.5785</td><td style=\"text-align: right;\">         0.334433</td><td style=\"text-align: right;\">             0.8     </td><td style=\"text-align: right;\">       0.381511</td></tr>\n",
       "<tr><td>train_dishs_6f5bd81b</td><td>TERMINATED</td><td>172.18.58.174:648083</td><td style=\"text-align: right;\">            0.546157</td><td style=\"text-align: right;\">    4.32387 </td><td style=\"text-align: right;\">0.0188463  </td><td style=\"text-align: right;\">  0.53731 </td><td style=\"text-align: right;\">    0.0485537 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.0774</td><td style=\"text-align: right;\">         0.285674</td><td style=\"text-align: right;\">             0.9     </td><td style=\"text-align: right;\">       0.602672</td></tr>\n",
       "<tr><td>train_dishs_8a9b5f1a</td><td>TERMINATED</td><td>172.18.58.174:651088</td><td style=\"text-align: right;\">            0.521432</td><td style=\"text-align: right;\">    3.09417 </td><td style=\"text-align: right;\">9.68673e-05</td><td style=\"text-align: right;\">  0.561705</td><td style=\"text-align: right;\">    0.0221033 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.8705</td><td style=\"text-align: right;\">         0.773991</td><td style=\"text-align: right;\">             0.533333</td><td style=\"text-align: right;\">       0.695179</td></tr>\n",
       "<tr><td>train_dishs_1205f36a</td><td>TERMINATED</td><td>172.18.58.174:654083</td><td style=\"text-align: right;\">            0.693234</td><td style=\"text-align: right;\">    1.3135  </td><td style=\"text-align: right;\">0.0570686  </td><td style=\"text-align: right;\">  0.701218</td><td style=\"text-align: right;\">    0.0371985 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         17.9722</td><td style=\"text-align: right;\">         0.31281 </td><td style=\"text-align: right;\">             0.9     </td><td style=\"text-align: right;\">       0.635893</td></tr>\n",
       "<tr><td>train_dishs_e8b81837</td><td>TERMINATED</td><td>172.18.58.174:657088</td><td style=\"text-align: right;\">            0.620694</td><td style=\"text-align: right;\">    4.7586  </td><td style=\"text-align: right;\">0.000800968</td><td style=\"text-align: right;\">  0.603614</td><td style=\"text-align: right;\">    0.0849824 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.012 </td><td style=\"text-align: right;\">         0.669288</td><td style=\"text-align: right;\">             0.633333</td><td style=\"text-align: right;\">       0.701633</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_dishs pid=545906)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/glucas11/ray_results/train_dishs_2024-06-15_14-43-16/train_dishs_35efa26e_3_classifier_dropout=0.5854,clip_value=2.2411,lr=0.0426,momentum=0.7087,weight_decay=0.0405_2024-06-15_14-43-41/checkpoint_000000)\n",
      "\u001b[36m(train_dishs pid=600019)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/glucas11/ray_results/train_dishs_2024-06-15_14-43-16/train_dishs_048a4f4a_21_classifier_dropout=0.5445,clip_value=3.2612,lr=0.0167,momentum=0.6000,weight_decay=0.0492_2024-06-15_14-49-56/checkpoint_000000)\n",
      "\u001b[36m(train_dishs pid=603026)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/glucas11/ray_results/train_dishs_2024-06-15_14-43-16/train_dishs_beef41ed_22_classifier_dropout=0.5672,clip_value=2.2676,lr=0.0237,momentum=0.8757,weight_decay=0.0641_2024-06-15_14-50-17/checkpoint_000000)\n",
      "\u001b[36m(train_dishs pid=645077)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/glucas11/ray_results/train_dishs_2024-06-15_14-43-16/train_dishs_05aceac8_36_classifier_dropout=0.5438,clip_value=3.2730,lr=0.0159,momentum=0.5842,weight_decay=0.0253_2024-06-15_14-55-05/checkpoint_000000)\n",
      "2024-06-15 14:57:06,991\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/glucas11/ray_results/train_dishs_2024-06-15_14-43-16' in 0.0081s.\n",
      "2024-06-15 14:57:07,001\tINFO tune.py:1041 -- Total run time: 828.03 seconds (827.99 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -10, -1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"classifier_dropout\": hp.uniform(\"classifier_dropout\", 0.5, 0.95),\n",
    "    \"weight_decay\": hp.loguniform(\"weight_decay\", -6, -2),\n",
    "    \"clip_value\": hp.uniform(\"clip_value\", 0.1, 5.0),\n",
    "}\n",
    "\n",
    "hyperopt_search = HyperOptSearch(space, metric=\"val_mean_accuracy\", mode=\"max\")\n",
    "\n",
    "trainable_with_resources = tune.with_resources(train_dishs, {\"gpu\": 1})\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=40,\n",
    "        search_alg=hyperopt_search,\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_mean_loss': 0.8232114315032959,\n",
       " 'train_mean_accuracy': 0.36666666666666664,\n",
       " 'val_mean_loss': 0.6398330926895142,\n",
       " 'val_mean_accuracy': 0.9,\n",
       " 'timestamp': 1718477039,\n",
       " 'checkpoint_dir_name': None,\n",
       " 'done': True,\n",
       " 'training_iteration': 20,\n",
       " 'trial_id': '3734e601',\n",
       " 'date': '2024-06-15_14-43-59',\n",
       " 'time_this_iter_s': 0.8173401355743408,\n",
       " 'time_total_s': 17.64312481880188,\n",
       " 'pid': 542905,\n",
       " 'hostname': 'DESKTOP-GF0BL1G',\n",
       " 'node_ip': '172.18.58.174',\n",
       " 'config': {'classifier_dropout': 0.5478954482088054,\n",
       "  'clip_value': 4.506712382652889,\n",
       "  'lr': 5.9951265748155445e-05,\n",
       "  'momentum': 0.5702254199292307,\n",
       "  'weight_decay': 0.012588494586609216},\n",
       " 'time_since_restore': 17.64312481880188,\n",
       " 'iterations_since_restore': 20,\n",
       " 'experiment_tag': '2_classifier_dropout=0.5479,clip_value=4.5067,lr=0.0001,momentum=0.5702,weight_decay=0.0126'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = results.get_best_result(\"val_mean_accuracy\", mode=\"max\")\n",
    "best_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5445068891619167, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5445068891619167, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = results.get_best_result(\"val_mean_loss\", mode=\"min\")\n",
    "with best_result.checkpoint.as_directory() as checkpoint_dir:\n",
    "    state_dict = torch.load(os.path.join(checkpoint_dir, \"model.pth\"))\n",
    "\n",
    "model = get_transfer_learning_model(best_result.config['classifier_dropout']).to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def to_csv(model, batch_size=10):\n",
    "    model.eval()\n",
    "    PATH_TEST = os.path.join(curr_path, \"data/test/\")\n",
    "    test_file_names = os.listdir(PATH_TEST)\n",
    "    test_file_names.sort()\n",
    "\n",
    "    submission_csv = {\n",
    "        \"id\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "\n",
    "    for file_name in test_file_names:\n",
    "        id = file_name.split(\".\")[0]\n",
    "        test_input = Image.open(os.path.join(PATH_TEST, file_name))\n",
    "        test_input = data_transforms['test'](test_input).to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred_test_label = model(test_input).max(1).indices.item()\n",
    "            pred_test_label = class_names[pred_test_label]\n",
    "        submission_csv['id'].append(id)\n",
    "        submission_csv['label'].append(pred_test_label)\n",
    "\n",
    "    submission_csv = pd.DataFrame(submission_csv).set_index(\"id\")\n",
    "    submission_csv.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- epoch: 1/100 ----------\n",
      "train: {'mean_loss': 0.8157494068145752, 'mean_accuracy': 0.5333333333333333}\n",
      "val: {'mean_loss': 0.5668608546257019, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 2/100 ----------\n",
      "train: {'mean_loss': 0.6545587778091431, 'mean_accuracy': 0.6}\n",
      "val: {'mean_loss': 0.7011714577674866, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 3/100 ----------\n",
      "train: {'mean_loss': 0.8297837972640991, 'mean_accuracy': 0.5666666666666667}\n",
      "val: {'mean_loss': 0.6197863817214966, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 4/100 ----------\n",
      "train: {'mean_loss': 0.6733068227767944, 'mean_accuracy': 0.6}\n",
      "val: {'mean_loss': 0.8567941784858704, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 5/100 ----------\n",
      "train: {'mean_loss': 0.6254743933677673, 'mean_accuracy': 0.6}\n",
      "val: {'mean_loss': 0.6771092414855957, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 6/100 ----------\n",
      "train: {'mean_loss': 0.6015492081642151, 'mean_accuracy': 0.7}\n",
      "val: {'mean_loss': 0.7042109370231628, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 7/100 ----------\n",
      "train: {'mean_loss': 0.667199969291687, 'mean_accuracy': 0.6333333333333333}\n",
      "val: {'mean_loss': 0.7217740416526794, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 8/100 ----------\n",
      "train: {'mean_loss': 0.8030171394348145, 'mean_accuracy': 0.5}\n",
      "val: {'mean_loss': 0.6552180647850037, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 9/100 ----------\n",
      "train: {'mean_loss': 0.6267447471618652, 'mean_accuracy': 0.6333333333333333}\n",
      "val: {'mean_loss': 0.6872376203536987, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 10/100 ----------\n",
      "train: {'mean_loss': 0.6090505719184875, 'mean_accuracy': 0.5666666666666667}\n",
      "val: {'mean_loss': 0.5420920252799988, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 11/100 ----------\n",
      "train: {'mean_loss': 0.5526948571205139, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5633355975151062, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 12/100 ----------\n",
      "train: {'mean_loss': 0.5082813501358032, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.5849327445030212, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 13/100 ----------\n",
      "train: {'mean_loss': 0.5148454308509827, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.6346668601036072, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 14/100 ----------\n",
      "train: {'mean_loss': 0.6106613278388977, 'mean_accuracy': 0.6666666666666666}\n",
      "val: {'mean_loss': 0.6663904190063477, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 15/100 ----------\n",
      "train: {'mean_loss': 0.5304891467094421, 'mean_accuracy': 0.6666666666666666}\n",
      "val: {'mean_loss': 0.678846001625061, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 16/100 ----------\n",
      "train: {'mean_loss': 0.49279969930648804, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.5170534253120422, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 17/100 ----------\n",
      "train: {'mean_loss': 0.5150982737541199, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.934500515460968, 'mean_accuracy': 0.5}\n",
      "---------- epoch: 18/100 ----------\n",
      "train: {'mean_loss': 0.49869975447654724, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.6402443051338196, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 19/100 ----------\n",
      "train: {'mean_loss': 0.3476245701313019, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.589677095413208, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 20/100 ----------\n",
      "train: {'mean_loss': 0.40917283296585083, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.47968369722366333, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 21/100 ----------\n",
      "train: {'mean_loss': 0.5002830028533936, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5201475024223328, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 22/100 ----------\n",
      "train: {'mean_loss': 0.5146470069885254, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.397756427526474, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 23/100 ----------\n",
      "train: {'mean_loss': 0.5323524475097656, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5229530930519104, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 24/100 ----------\n",
      "train: {'mean_loss': 0.5606945753097534, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5571826100349426, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 25/100 ----------\n",
      "train: {'mean_loss': 0.36835023760795593, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.32560765743255615, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 26/100 ----------\n",
      "train: {'mean_loss': 0.29073405265808105, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.351591020822525, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 27/100 ----------\n",
      "train: {'mean_loss': 0.43817397952079773, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5463443398475647, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 28/100 ----------\n",
      "train: {'mean_loss': 0.3675382137298584, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.52742999792099, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 29/100 ----------\n",
      "train: {'mean_loss': 0.44078049063682556, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.748985767364502, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 30/100 ----------\n",
      "train: {'mean_loss': 0.3505956530570984, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.621224045753479, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 31/100 ----------\n",
      "train: {'mean_loss': 0.32702675461769104, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.6319427490234375, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 32/100 ----------\n",
      "train: {'mean_loss': 0.25400030612945557, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.9278813600540161, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 33/100 ----------\n",
      "train: {'mean_loss': 0.39983925223350525, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.7337296605110168, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 34/100 ----------\n",
      "train: {'mean_loss': 0.270808607339859, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5428431630134583, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 35/100 ----------\n",
      "train: {'mean_loss': 0.3393822908401489, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.5138512253761292, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 36/100 ----------\n",
      "train: {'mean_loss': 0.36916041374206543, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.48224741220474243, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 37/100 ----------\n",
      "train: {'mean_loss': 0.276445209980011, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5638130307197571, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 38/100 ----------\n",
      "train: {'mean_loss': 0.4622000753879547, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.43705281615257263, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 39/100 ----------\n",
      "train: {'mean_loss': 0.35225069522857666, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.5229447484016418, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 40/100 ----------\n",
      "train: {'mean_loss': 0.3088032603263855, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.6135511994361877, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 41/100 ----------\n",
      "train: {'mean_loss': 0.3988996148109436, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.44757500290870667, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 42/100 ----------\n",
      "train: {'mean_loss': 0.18620876967906952, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.09965108335018158, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 43/100 ----------\n",
      "train: {'mean_loss': 0.2471615970134735, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.8777470588684082, 'mean_accuracy': 0.5}\n",
      "---------- epoch: 44/100 ----------\n",
      "train: {'mean_loss': 0.3393841087818146, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5096102356910706, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 45/100 ----------\n",
      "train: {'mean_loss': 0.5302120447158813, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.3260535001754761, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 46/100 ----------\n",
      "train: {'mean_loss': 0.153019979596138, 'mean_accuracy': 1.0}\n",
      "val: {'mean_loss': 0.36816713213920593, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 47/100 ----------\n",
      "train: {'mean_loss': 0.20280778408050537, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.6957297921180725, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 48/100 ----------\n",
      "train: {'mean_loss': 0.602501392364502, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.8548914790153503, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 49/100 ----------\n",
      "train: {'mean_loss': 0.27165165543556213, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.3610256314277649, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 50/100 ----------\n",
      "train: {'mean_loss': 0.32029998302459717, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.61543208360672, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 51/100 ----------\n",
      "train: {'mean_loss': 0.2821118235588074, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5619309544563293, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 52/100 ----------\n",
      "train: {'mean_loss': 0.4202415645122528, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.2112438976764679, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 53/100 ----------\n",
      "train: {'mean_loss': 0.18513323366641998, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.569156289100647, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 54/100 ----------\n",
      "train: {'mean_loss': 0.3767054080963135, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.48969751596450806, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 55/100 ----------\n",
      "train: {'mean_loss': 0.20392870903015137, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.6635038256645203, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 56/100 ----------\n",
      "train: {'mean_loss': 0.29263004660606384, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.41156306862831116, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 57/100 ----------\n",
      "train: {'mean_loss': 0.25486719608306885, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5056336522102356, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 58/100 ----------\n",
      "train: {'mean_loss': 0.43456900119781494, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.4208155572414398, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 59/100 ----------\n",
      "train: {'mean_loss': 0.24527692794799805, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.28857582807540894, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 60/100 ----------\n",
      "train: {'mean_loss': 0.29693618416786194, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.6848024129867554, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 61/100 ----------\n",
      "train: {'mean_loss': 0.1184026300907135, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.35771963000297546, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 62/100 ----------\n",
      "train: {'mean_loss': 0.4624447226524353, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.35789433121681213, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 63/100 ----------\n",
      "train: {'mean_loss': 0.19902430474758148, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.6325888633728027, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 64/100 ----------\n",
      "train: {'mean_loss': 0.22935770452022552, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.9519938826560974, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 65/100 ----------\n",
      "train: {'mean_loss': 0.4196180999279022, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.4823720157146454, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 66/100 ----------\n",
      "train: {'mean_loss': 0.5518902540206909, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.10229998826980591, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 67/100 ----------\n",
      "train: {'mean_loss': 0.2269221395254135, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.42196279764175415, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 68/100 ----------\n",
      "train: {'mean_loss': 0.23866038024425507, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.3829043507575989, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 69/100 ----------\n",
      "train: {'mean_loss': 0.12874214351177216, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.37242239713668823, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 70/100 ----------\n",
      "train: {'mean_loss': 0.1914624571800232, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 1.137717843055725, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 71/100 ----------\n",
      "train: {'mean_loss': 0.6468943357467651, 'mean_accuracy': 0.7}\n",
      "val: {'mean_loss': 0.5029745697975159, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 72/100 ----------\n",
      "train: {'mean_loss': 0.2671683728694916, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.600611686706543, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 73/100 ----------\n",
      "train: {'mean_loss': 0.28825390338897705, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.715667188167572, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 74/100 ----------\n",
      "train: {'mean_loss': 0.22889888286590576, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.18871556222438812, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 75/100 ----------\n",
      "train: {'mean_loss': 0.1851157397031784, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.3379116952419281, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 76/100 ----------\n",
      "train: {'mean_loss': 0.508331298828125, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.6475067734718323, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 77/100 ----------\n",
      "train: {'mean_loss': 0.3020841181278229, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.6786695718765259, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 78/100 ----------\n",
      "train: {'mean_loss': 0.24684759974479675, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.5625050067901611, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 79/100 ----------\n",
      "train: {'mean_loss': 0.35742348432540894, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.405501127243042, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 80/100 ----------\n",
      "train: {'mean_loss': 0.17196208238601685, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5718386769294739, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 81/100 ----------\n",
      "train: {'mean_loss': 0.31311362981796265, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.6491380333900452, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 82/100 ----------\n",
      "train: {'mean_loss': 0.4445032775402069, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.3542652130126953, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 83/100 ----------\n",
      "train: {'mean_loss': 0.2790071666240692, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.5297986268997192, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 84/100 ----------\n",
      "train: {'mean_loss': 0.28335142135620117, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5824911594390869, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 85/100 ----------\n",
      "train: {'mean_loss': 0.3330295979976654, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5212599635124207, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 86/100 ----------\n",
      "train: {'mean_loss': 0.32468488812446594, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.49375730752944946, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 87/100 ----------\n",
      "train: {'mean_loss': 0.14125652611255646, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.5607758164405823, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 88/100 ----------\n",
      "train: {'mean_loss': 0.15431921184062958, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.11794676631689072, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 89/100 ----------\n",
      "train: {'mean_loss': 0.163399338722229, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.9966238141059875, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 90/100 ----------\n",
      "train: {'mean_loss': 0.6512425541877747, 'mean_accuracy': 0.6666666666666666}\n",
      "val: {'mean_loss': 0.3140730857849121, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 91/100 ----------\n",
      "train: {'mean_loss': 0.20105716586112976, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.4681704044342041, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 92/100 ----------\n",
      "train: {'mean_loss': 0.12744614481925964, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.0912974551320076, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 93/100 ----------\n",
      "train: {'mean_loss': 0.26065248250961304, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 1.081428050994873, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 94/100 ----------\n",
      "train: {'mean_loss': 0.6768153309822083, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.3339903950691223, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 95/100 ----------\n",
      "train: {'mean_loss': 0.19791465997695923, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.39347055554389954, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 96/100 ----------\n",
      "train: {'mean_loss': 0.14331020414829254, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.43803101778030396, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 97/100 ----------\n",
      "train: {'mean_loss': 0.20223218202590942, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.5638999342918396, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 98/100 ----------\n",
      "train: {'mean_loss': 0.4300920069217682, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.19706980884075165, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 99/100 ----------\n",
      "train: {'mean_loss': 0.47883155941963196, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5779322981834412, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 100/100 ----------\n",
      "train: {'mean_loss': 0.2944470942020416, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.6595021486282349, 'mean_accuracy': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_config_train_model = train_dishs(best_result.config, max_epochs=100, tunning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = best_config_train_model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.7594161951487975, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.7594161951487975, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
