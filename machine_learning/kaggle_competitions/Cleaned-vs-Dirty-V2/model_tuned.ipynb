{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_path = os.path.abspath(os.getcwd())\n",
    "data_path = os.path.join(curr_path, \"plates\")\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if not os.path.isdir(data_path):\n",
    "    !unzip {curr_path}/platesv2.zip -d {curr_path}/platesv2/\n",
    "    !unzip {curr_path}/platesv2/plates.zip -d {curr_path}/tmp_plates/\n",
    "    !mv {curr_path}/tmp_plates/plates/ {curr_path}/plates/\n",
    "    !find {curr_path}/plates -name '.DS_Store' -type f -delete\n",
    "    !rm -r {curr_path}/platesv2/\n",
    "    !rm -r {curr_path}/tmp_plates\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "def create_val_dataset(val_size=0.3):\n",
    "    random.seed(\"happy :)\")\n",
    "\n",
    "    train_path = os.path.join(data_path, \"train\")\n",
    "    val_path = os.path.join(data_path, \"val\")\n",
    "    try:\n",
    "        os.mkdir(val_path)\n",
    "    except FileExistsError:\n",
    "        print(\"val already exist\")\n",
    "        return\n",
    "    \n",
    "    classes_name = os.listdir(train_path)\n",
    "    for class_name in classes_name:\n",
    "        class_path = os.path.join(train_path, class_name)\n",
    "        images_filename = os.listdir(class_path)\n",
    "        sample_size = int(val_size * len(images_filename))\n",
    "        selected_val_images = random.sample(images_filename, sample_size)\n",
    "        \n",
    "        new_class_path = os.path.join(val_path, class_name)\n",
    "        os.mkdir(new_class_path)\n",
    "        [shutil.move(os.path.join(class_path, image_filename),new_class_path) for image_filename in selected_val_images]\n",
    "\n",
    "create_val_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def extract_plate_with_grabcut(image_path):\n",
    "#     image = cv2.imread(image_path)\n",
    "#     mask = np.zeros(image.shape[:2], np.uint8)\n",
    "#     bgd_model = np.zeros((1, 65), np.float64)\n",
    "#     fgd_model = np.zeros((1, 65), np.float64)\n",
    "#     height, width = image.shape[:2]\n",
    "#     rect = (int(width*0.1), int(height*0.1), int(width*0.8), int(height*0.8))\n",
    "#     cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "#     mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "#     result = image * mask2[:, :, np.newaxis]\n",
    "#     contours, _ = cv2.findContours(mask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     if contours:\n",
    "#         largest_contour = max(contours, key=cv2.contourArea)\n",
    "#         x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "#         cropped_result = result[y:y+h, x:x+w]\n",
    "#     else:\n",
    "#         cropped_result = result\n",
    "#     return cropped_result\n",
    "\n",
    "# def extract_class_bg(class_path):\n",
    "#     imgs_filename = os.listdir(class_path)\n",
    "#     for img_filename in imgs_filename:\n",
    "\n",
    "#         # remove image background\n",
    "#         img_path = os.path.join(class_path, img_filename)\n",
    "#         print(img_path)\n",
    "#         extracted_plate = extract_plate_with_grabcut(img_path)\n",
    "\n",
    "#         # save img into new dataset path\n",
    "#         cv2.imwrite(img_path, extracted_plate)\n",
    "\n",
    "# def remove_datasets_background():\n",
    "#     datasets_names = os.listdir(data_path)\n",
    "\n",
    "#     for dataset_name in datasets_names:\n",
    "\n",
    "#         dataset_path = os.path.join(data_path, dataset_name)\n",
    "#         if dataset_name == \"test\":\n",
    "#             extract_class_bg(dataset_path)\n",
    "#         else:\n",
    "#             classes_names = os.listdir(dataset_path)\n",
    "\n",
    "#             for class_name in classes_names:\n",
    "\n",
    "#                 # get class path\n",
    "#                 class_path = os.path.join(dataset_path, class_name)\n",
    "\n",
    "#                 extract_class_bg(class_path)\n",
    "                \n",
    "# remove_datasets_background()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_learning_model(classifier_dropout, image_net):\n",
    "    model = models.resnet152(weights=image_net)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(classifier_dropout, inplace=True),\n",
    "        nn.Linear(model.fc.in_features, 2),\n",
    "    )\n",
    "\n",
    "    # for layer in model.classifier:\n",
    "    #     if isinstance(layer, nn.Dropout):\n",
    "    #         layer.p = classifier_dropout\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, dataset, n_batch_size, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.n_batch_size = n_batch_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of batches times the batch size\n",
    "        return len(self.dataset) * (self.n_batch_size // len(self.dataset))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the original image and label\n",
    "        img, label = self.dataset[idx % len(self.dataset)]\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "target_transforms = transforms.Compose([\n",
    "    lambda x:torch.tensor(x), # or just torch.tensor\n",
    "    lambda x:F.one_hot(x,2),\n",
    "])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # transforms.RandomRotation(degrees=(0, 360)),\n",
    "        # transforms.RandomResizedCrop(256, scale=(0.5, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        # transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomVerticalFlip(),\n",
    "        # transforms.ColorJitter(brightness=(0.3, 1)),\n",
    "        # # transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "        # transforms.RandomEqualize(),\n",
    "        # transforms.RandomGrayscale(p=0.2),\n",
    "        # transforms.CenterCrop(224),\n",
    "        # transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.RandomPerspective(distortion_scale=0.09, p=0.75, interpolation=3, fill=255),\n",
    "        transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.RandomResizedCrop(232, scale=(0.5, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ColorJitter(hue=(-0.5,0.5)),\n",
    "        transforms.RandomEqualize(),\n",
    "        # transforms.RandomGrayscale(p=0.2),\n",
    "        #transforms.RandomGrayscale(p=1),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        # transforms.RandomRotation(degrees=(0, 360)),\n",
    "        # transforms.RandomResizedCrop(256, scale=(0.8, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        # transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomVerticalFlip(),\n",
    "        # transforms.ColorJitter(brightness=(0.3, 1)),\n",
    "        # # transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "        # transforms.RandomEqualize(),\n",
    "        # transforms.RandomGrayscale(p=0.2),\n",
    "        # transforms.CenterCrop(224),\n",
    "        # transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        transforms.RandomPerspective(distortion_scale=0.1, p=0.8, interpolation=3, fill=255),\n",
    "        transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.RandomResizedCrop(232, scale=(0.05, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ColorJitter(hue=(-0.5,0.5)),\n",
    "        transforms.RandomEqualize(),\n",
    "        # transforms.RandomGrayscale(p=0.2),\n",
    "        #transforms.RandomGrayscale(p=1),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(232, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "data_dir = data_path\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),target_transform=target_transforms)\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "augmented_dataset = {\n",
    "    x: AugmentedDataset(image_datasets[x], 50, transform=data_transforms[x])\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "dataloaders = {x: DataLoader(augmented_dataset[x], batch_size=50,\n",
    "                                             shuffle=True, num_workers=10)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(inp,)\n",
    "    #if title is not None:\n",
    "    #    plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "phases = ['train','val']\n",
    "for phase in phases:\n",
    "    print(phase)\n",
    "    for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "        # Get a batch of training data\n",
    "        inputs, classes = next(iter(dataloaders[phase]))\n",
    "        classes = classes.max(axis=1)[1]\n",
    "        \n",
    "        # Make a grid from batch\n",
    "        out = make_grid(inputs)\n",
    "\n",
    "        imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, optimizer, exp_lr_scheduler, clip_value):\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(dataloaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target.float())\n",
    "\n",
    "        total += output.size(0)\n",
    "        running_loss += loss.item() * output.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        _, correct_class = torch.max(target.data, 1)\n",
    "        \n",
    "        correct += (predicted == correct_class).sum().item()\n",
    "    \n",
    "    exp_lr_scheduler.step()\n",
    "    \n",
    "    return {\n",
    "        \"mean_loss\": running_loss / total,\n",
    "        \"mean_accuracy\": correct / total,\n",
    "    }\n",
    "\n",
    "def test_func(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(dataloaders['val']):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "\n",
    "            # accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, correct_class = torch.max(target.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == correct_class).sum().item()\n",
    "\n",
    "            # loss\n",
    "            running_loss += F.cross_entropy(outputs, target.float()).item() * outputs.size(0)\n",
    "    \n",
    "    return {\n",
    "        \"mean_loss\": running_loss / total,\n",
    "        \"mean_accuracy\": correct / total,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "def train_dishs(config, max_epochs=30, tunning=True):\n",
    "    \n",
    "    # Data Setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = get_transfer_learning_model(config['classifier_dropout'], config['image_net'])\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config['weight_decay'])\n",
    "    \n",
    "    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=config['lr_scheduler_gamma'])\n",
    "    for i in range(max_epochs):\n",
    "        train_log = train_func(model, optimizer, exp_lr_scheduler, config['clip_value'])\n",
    "        val_log = test_func(model)\n",
    "\n",
    "        if tunning:\n",
    "            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "                checkpoint = None\n",
    "                if (i + 1) % max_epochs == 0 and (val_log[\"mean_loss\"] < 0.4):\n",
    "                    # This saves the model to the trial directory\n",
    "                    torch.save(\n",
    "                        model.state_dict(),\n",
    "                        os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
    "                    )\n",
    "                    checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "                # Send the current training result back to Tune\n",
    "                train.report(\n",
    "                    {\n",
    "                        \"train_mean_loss\": train_log[\"mean_loss\"],\n",
    "                        \"train_mean_accuracy\": train_log[\"mean_accuracy\"],\n",
    "                        \"val_mean_loss\": val_log[\"mean_loss\"],\n",
    "                        \"val_mean_accuracy\": val_log[\"mean_accuracy\"],\n",
    "                    },\n",
    "                    checkpoint=checkpoint\n",
    "                )\n",
    "        else:\n",
    "            print(\"-\"*10, f\"epoch: {i+1}/{max_epochs}\",\"-\"*10)\n",
    "            print(f\"train: {train_log}\\nval: {val_log}\")\n",
    "    if not tunning:\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"log\": {\n",
    "                \"train\": train_log,\n",
    "                \"val\": val_log,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    with open(\"best_result.json\", \"r\") as f:\n",
    "        curr_best_params = [json.load(f)]\n",
    "except:\n",
    "    curr_best_params = None\n",
    "\n",
    "curr_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -3, -1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"classifier_dropout\": hp.uniform(\"classifier_dropout\", 0.5, 0.95),\n",
    "    \"weight_decay\": hp.loguniform(\"weight_decay\", -6, -2),\n",
    "    \"clip_value\": hp.randint(\"clip_value\", 1, 5+1),\n",
    "    \"lr_scheduler_gamma\": hp.uniform(\"lr_scheduler_gamma\", 0.5, 1.0),\n",
    "    \"image_net\": hp.choice(\"image_net\", [\"IMAGENET1K_V1\", \"IMAGENET1K_V2\"]),\n",
    "}\n",
    "\n",
    "metric = \"val_mean_accuracy\"\n",
    "mode = \"max\"\n",
    "\n",
    "hyperopt_search = HyperOptSearch(\n",
    "    space,\n",
    "    metric=metric,\n",
    "    mode=mode,\n",
    "    points_to_evaluate = curr_best_params\n",
    ")\n",
    "\n",
    "asas_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric=metric,\n",
    "    mode=mode,\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=3,\n",
    "    brackets=2\n",
    ")\n",
    "\n",
    "trainable_with_resources = tune.with_resources(train_dishs, {\"cpu\": 8, \"gpu\": 1})\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=40,\n",
    "        search_alg=hyperopt_search,\n",
    "        scheduler=asas_scheduler\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(\"val_mean_accuracy\", mode=\"max\")\n",
    "best_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"best_result.json\", 'w') as f:\n",
    "    json.dump(best_result.config, f, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_result = results.get_best_result(\"val_mean_loss\", mode=\"min\")\n",
    "# with best_result.checkpoint.as_directory() as checkpoint_dir:\n",
    "#     state_dict = torch.load(os.path.join(checkpoint_dir, \"model.pth\"))\n",
    "\n",
    "# model = get_transfer_learning_model(best_result.config['classifier_dropout']).to(device)\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.classifier\n",
    "# to_csv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def to_csv(model, batch_size=10):\n",
    "    model.eval()\n",
    "    PATH_TEST = os.path.join(data_path, \"test\")\n",
    "    test_file_names = os.listdir(PATH_TEST)\n",
    "    test_file_names.sort()\n",
    "\n",
    "    submission_csv = {\n",
    "        \"id\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "\n",
    "    for file_name in test_file_names:\n",
    "        id = file_name.split(\".\")[0]\n",
    "        test_input = Image.open(os.path.join(PATH_TEST, file_name))\n",
    "        test_input = data_transforms['test'](test_input).to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred_test_label = model(test_input).max(1).indices.item()\n",
    "            pred_test_label = class_names[pred_test_label]\n",
    "        submission_csv['id'].append(id)\n",
    "        submission_csv['label'].append(pred_test_label)\n",
    "\n",
    "    submission_csv = pd.DataFrame(submission_csv).set_index(\"id\")\n",
    "    submission_csv.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"best_result.json\", \"r\") as f:\n",
    "    best_config_loaded = json.load(f)\n",
    "\n",
    "best_config_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_train_model = train_dishs(best_config_loaded, max_epochs=10, tunning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = best_config_train_model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phases = ['train','val']\n",
    "# for phase in phases:\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "#     for inputs, labels in dataloaders[phase]:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "#         #calculate val loss\n",
    "#         outputs = new_model(inputs)\n",
    "#         loss = F.cross_entropy(outputs, labels.float()).item()\n",
    "#         print(loss)\n",
    "\n",
    "#         # Get a batch of training data\n",
    "#         classes = labels.max(axis=1)[1]\n",
    "#         pred_classes = outputs.max(axis=1)[1]\n",
    "#         print([class_names[i] for i in classes])\n",
    "#         print(pred_classes == classes)\n",
    "        \n",
    "#         # Make a grid from batch\n",
    "#         out = make_grid(inputs)\n",
    "\n",
    "#         imshow(out.cpu(), title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.get_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_plots = [\"lr\", \"weight_decay\"]\n",
    "def plot_scatter(data, x_param, y_param=\"val_mean_loss\"):\n",
    "    \n",
    "    if x_param == \"clip_value\":\n",
    "        data[f\"config/{x_param}\"] = np.array(data[f\"config/{x_param}\"], dtype=int)\n",
    "    sns.scatterplot(data=data, x=f'config/{x_param}', y=y_param)\n",
    "    plt.title(f'{x_param} vs. {y_param}')\n",
    "    plt.ylim(0,1.0)\n",
    "    #plt.yscale(\"log\")\n",
    "    if x_param in log_plots:\n",
    "        plt.xscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "# Create scatter plots for each hyperparameter\n",
    "plot_scatter(df, 'lr')\n",
    "plot_scatter(df, 'clip_value')\n",
    "plot_scatter(df, 'momentum')\n",
    "plot_scatter(df, 'classifier_dropout')\n",
    "plot_scatter(df, 'weight_decay')\n",
    "plot_scatter(df, 'lr_scheduler_gamma')\n",
    "plot_scatter(df, 'image_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./plates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
