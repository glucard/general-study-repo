{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_path = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_learning_model(classifier_dropout):\n",
    "    model_weights = models.VGG19_Weights.DEFAULT\n",
    "    model_ft = models.vgg19(weights=model_weights)\n",
    "\n",
    "    for param in model_ft.parameters():\n",
    "        # param.requires_grad = False\n",
    "        param.requires_grad = True\n",
    "\n",
    "    for param in model_ft.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    model_ft.classifier[-1] = nn.Linear(model_ft.classifier[-1].in_features, 2)\n",
    "\n",
    "    for layer in model_ft.classifier:\n",
    "        if isinstance(layer, nn.Dropout):\n",
    "            layer.p = classifier_dropout\n",
    "    \n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cleaned', 'dirty'], device(type='cuda', index=0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.utils\n",
    "\n",
    "target_transforms = transforms.Compose([\n",
    "    lambda x:torch.tensor(x), # or just torch.tensor\n",
    "    lambda x:F.one_hot(x,2)\n",
    "])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(0, 360)),\n",
    "        transforms.RandomResizedCrop(256, scale=(0.5, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=(0.3, 1)),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=(0, 360)),\n",
    "        transforms.RandomResizedCrop(256, scale=(0.8, 1), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.AutoAugment(policy=transforms.autoaugment.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=(0.3, 1)),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.0)),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = os.path.join(curr_path, \"data\")\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x], target_transform=target_transforms)\n",
    "                  for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# image_datasets['train'], image_datasets['val'] = torch.utils.data.random_split(image_datasets['train'], [30, 10])\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=50,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, optimizer, clip_value):\n",
    "    total = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(dataloaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target.float())\n",
    "\n",
    "        total += output.size(0)\n",
    "        running_loss += loss.item() * output.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        _, correct_class = torch.max(target.data, 1)\n",
    "        \n",
    "        correct += (predicted == correct_class).sum().item()\n",
    "    \n",
    "    return {\n",
    "        \"mean_loss\": running_loss / total,\n",
    "        \"mean_accuracy\": correct / total,\n",
    "    }\n",
    "\n",
    "def test_func(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(dataloaders['val']):\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "\n",
    "            # accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, correct_class = torch.max(target.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == correct_class).sum().item()\n",
    "\n",
    "            # loss\n",
    "            running_loss += F.cross_entropy(outputs, target.float()).item() * outputs.size(0)\n",
    "    \n",
    "    return {\n",
    "        \"mean_loss\": running_loss / total,\n",
    "        \"mean_accuracy\": correct / total,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from ray.train import Checkpoint\n",
    "\n",
    "def train_dishs(config, max_epochs=20, tunning=True):\n",
    "    # Data Setup\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = get_transfer_learning_model(config['classifier_dropout'])\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config['weight_decay'])\n",
    "    for i in range(max_epochs):\n",
    "        train_log = train_func(model, optimizer, config['clip_value'])\n",
    "        val_log = test_func(model)\n",
    "\n",
    "        if tunning:\n",
    "            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "                checkpoint = None\n",
    "                if (i + 1) % max_epochs == 0 and (val_log[\"mean_loss\"] < 0.4):\n",
    "                    # This saves the model to the trial directory\n",
    "                    torch.save(\n",
    "                        model.state_dict(),\n",
    "                        os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
    "                    )\n",
    "                    checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "                # Send the current training result back to Tune\n",
    "                train.report(\n",
    "                    {\n",
    "                        \"train_mean_loss\": train_log[\"mean_loss\"],\n",
    "                        \"train_mean_accuracy\": train_log[\"mean_accuracy\"],\n",
    "                        \"val_mean_loss\": val_log[\"mean_loss\"],\n",
    "                        \"val_mean_accuracy\": val_log[\"mean_accuracy\"],\n",
    "                    },\n",
    "                    checkpoint=checkpoint\n",
    "                )\n",
    "        else:\n",
    "            print(\"-\"*10, f\"epoch: {i+1}/{max_epochs}\",\"-\"*10)\n",
    "            print(f\"train: {train_log}\\nval: {val_log}\")\n",
    "    if not tunning:\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"log\": {\n",
    "                \"train\": train_log,\n",
    "                \"val\": val_log,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config = {\\n    \"lr\":0.1,\\n    \"momentum\":0.5,\\n}\\n\\ntrain_dishs(config)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"config = {\n",
    "    \"lr\":0.1,\n",
    "    \"momentum\":0.5,\n",
    "}\n",
    "\n",
    "train_dishs(config)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-15 14:15:17</td></tr>\n",
       "<tr><td>Running for: </td><td>00:15:51.85        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.4/15.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  classifier_dropout</th><th style=\"text-align: right;\">  clip_value</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_mean_loss</th><th style=\"text-align: right;\">  train_mean_accuracy</th><th style=\"text-align: right;\">  val_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_dishs_3ad12912</td><td>TERMINATED</td><td>172.18.58.174:388306</td><td style=\"text-align: right;\">            0.838715</td><td style=\"text-align: right;\">    4.34739 </td><td style=\"text-align: right;\">0.000670334</td><td style=\"text-align: right;\">  0.41329 </td><td style=\"text-align: right;\">    0.022106  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.2168</td><td style=\"text-align: right;\">         1.04291 </td><td style=\"text-align: right;\">             0.466667</td><td style=\"text-align: right;\">       0.723456</td></tr>\n",
       "<tr><td>train_dishs_bf2fb1dc</td><td>TERMINATED</td><td>172.18.58.174:391356</td><td style=\"text-align: right;\">            0.878274</td><td style=\"text-align: right;\">    1.67659 </td><td style=\"text-align: right;\">0.000233061</td><td style=\"text-align: right;\">  0.221804</td><td style=\"text-align: right;\">    0.00454917</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         21.7716</td><td style=\"text-align: right;\">         1.0005  </td><td style=\"text-align: right;\">             0.466667</td><td style=\"text-align: right;\">       0.768805</td></tr>\n",
       "<tr><td>train_dishs_8b7524b5</td><td>TERMINATED</td><td>172.18.58.174:394378</td><td style=\"text-align: right;\">            0.849991</td><td style=\"text-align: right;\">    4.74447 </td><td style=\"text-align: right;\">0.000438618</td><td style=\"text-align: right;\">  0.349805</td><td style=\"text-align: right;\">    0.0159287 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         27.4166</td><td style=\"text-align: right;\">         1.07896 </td><td style=\"text-align: right;\">             0.4     </td><td style=\"text-align: right;\">       0.740682</td></tr>\n",
       "<tr><td>train_dishs_2e461696</td><td>TERMINATED</td><td>172.18.58.174:397444</td><td style=\"text-align: right;\">            0.731665</td><td style=\"text-align: right;\">    0.944569</td><td style=\"text-align: right;\">0.000170583</td><td style=\"text-align: right;\">  0.784582</td><td style=\"text-align: right;\">    0.00798063</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.3307</td><td style=\"text-align: right;\">         0.72301 </td><td style=\"text-align: right;\">             0.5     </td><td style=\"text-align: right;\">       0.730685</td></tr>\n",
       "<tr><td>train_dishs_e5f799c3</td><td>TERMINATED</td><td>172.18.58.174:400454</td><td style=\"text-align: right;\">            0.546397</td><td style=\"text-align: right;\">    4.01981 </td><td style=\"text-align: right;\">0.00162157 </td><td style=\"text-align: right;\">  0.257456</td><td style=\"text-align: right;\">    0.00266262</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1602</td><td style=\"text-align: right;\">         0.581299</td><td style=\"text-align: right;\">             0.766667</td><td style=\"text-align: right;\">       0.64927 </td></tr>\n",
       "<tr><td>train_dishs_14308d97</td><td>TERMINATED</td><td>172.18.58.174:403471</td><td style=\"text-align: right;\">            0.872002</td><td style=\"text-align: right;\">    3.93005 </td><td style=\"text-align: right;\">0.00214131 </td><td style=\"text-align: right;\">  0.565053</td><td style=\"text-align: right;\">    0.0161657 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.0836</td><td style=\"text-align: right;\">         0.76815 </td><td style=\"text-align: right;\">             0.533333</td><td style=\"text-align: right;\">       0.783966</td></tr>\n",
       "<tr><td>train_dishs_45df32ce</td><td>TERMINATED</td><td>172.18.58.174:406475</td><td style=\"text-align: right;\">            0.835385</td><td style=\"text-align: right;\">    1.02255 </td><td style=\"text-align: right;\">0.0376528  </td><td style=\"text-align: right;\">  0.575329</td><td style=\"text-align: right;\">    0.125749  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1548</td><td style=\"text-align: right;\">         0.659917</td><td style=\"text-align: right;\">             0.533333</td><td style=\"text-align: right;\">       0.652451</td></tr>\n",
       "<tr><td>train_dishs_bf3d6216</td><td>TERMINATED</td><td>172.18.58.174:409480</td><td style=\"text-align: right;\">            0.545027</td><td style=\"text-align: right;\">    4.88107 </td><td style=\"text-align: right;\">0.119672   </td><td style=\"text-align: right;\">  0.382093</td><td style=\"text-align: right;\">    0.0058665 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1144</td><td style=\"text-align: right;\">         1.07326 </td><td style=\"text-align: right;\">             0.4     </td><td style=\"text-align: right;\">       4.29633 </td></tr>\n",
       "<tr><td>train_dishs_3af69f1c</td><td>TERMINATED</td><td>172.18.58.174:412485</td><td style=\"text-align: right;\">            0.739429</td><td style=\"text-align: right;\">    3.13053 </td><td style=\"text-align: right;\">0.00293688 </td><td style=\"text-align: right;\">  0.411806</td><td style=\"text-align: right;\">    0.0295035 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.2083</td><td style=\"text-align: right;\">         0.654154</td><td style=\"text-align: right;\">             0.6     </td><td style=\"text-align: right;\">       0.65492 </td></tr>\n",
       "<tr><td>train_dishs_cb6c9b56</td><td>TERMINATED</td><td>172.18.58.174:415492</td><td style=\"text-align: right;\">            0.76873 </td><td style=\"text-align: right;\">    2.28598 </td><td style=\"text-align: right;\">0.209911   </td><td style=\"text-align: right;\">  0.501896</td><td style=\"text-align: right;\">    0.0159385 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1519</td><td style=\"text-align: right;\">         0.825879</td><td style=\"text-align: right;\">             0.466667</td><td style=\"text-align: right;\">       0.720903</td></tr>\n",
       "<tr><td>train_dishs_bc94d1f4</td><td>TERMINATED</td><td>172.18.58.174:418497</td><td style=\"text-align: right;\">            0.801411</td><td style=\"text-align: right;\">    1.33466 </td><td style=\"text-align: right;\">0.218185   </td><td style=\"text-align: right;\">  0.227152</td><td style=\"text-align: right;\">    0.0621282 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1685</td><td style=\"text-align: right;\">         1.02353 </td><td style=\"text-align: right;\">             0.5     </td><td style=\"text-align: right;\">       0.77576 </td></tr>\n",
       "<tr><td>train_dishs_61d47a8c</td><td>TERMINATED</td><td>172.18.58.174:421502</td><td style=\"text-align: right;\">            0.765705</td><td style=\"text-align: right;\">    3.03003 </td><td style=\"text-align: right;\">7.99583e-05</td><td style=\"text-align: right;\">  0.388441</td><td style=\"text-align: right;\">    0.0257436 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.1078</td><td style=\"text-align: right;\">         0.811539</td><td style=\"text-align: right;\">             0.566667</td><td style=\"text-align: right;\">       0.711988</td></tr>\n",
       "<tr><td>train_dishs_1b4d8e35</td><td>TERMINATED</td><td>172.18.58.174:424507</td><td style=\"text-align: right;\">            0.588283</td><td style=\"text-align: right;\">    3.14338 </td><td style=\"text-align: right;\">0.122424   </td><td style=\"text-align: right;\">  0.206826</td><td style=\"text-align: right;\">    0.00247926</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         23.2809</td><td style=\"text-align: right;\">         0.649812</td><td style=\"text-align: right;\">             0.633333</td><td style=\"text-align: right;\">       1.06498 </td></tr>\n",
       "<tr><td>train_dishs_478a433b</td><td>TERMINATED</td><td>172.18.58.174:427549</td><td style=\"text-align: right;\">            0.620361</td><td style=\"text-align: right;\">    1.12877 </td><td style=\"text-align: right;\">0.234492   </td><td style=\"text-align: right;\">  0.780645</td><td style=\"text-align: right;\">    0.00560839</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         27.3414</td><td style=\"text-align: right;\">         0.75636 </td><td style=\"text-align: right;\">             0.5     </td><td style=\"text-align: right;\">       0.697202</td></tr>\n",
       "<tr><td>train_dishs_c236887a</td><td>TERMINATED</td><td>172.18.58.174:430615</td><td style=\"text-align: right;\">            0.903738</td><td style=\"text-align: right;\">    0.920388</td><td style=\"text-align: right;\">0.259967   </td><td style=\"text-align: right;\">  0.85464 </td><td style=\"text-align: right;\">    0.00722422</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         27.2123</td><td style=\"text-align: right;\">         0.934889</td><td style=\"text-align: right;\">             0.466667</td><td style=\"text-align: right;\">       0.69113 </td></tr>\n",
       "<tr><td>train_dishs_d336db58</td><td>TERMINATED</td><td>172.18.58.174:433694</td><td style=\"text-align: right;\">            0.846153</td><td style=\"text-align: right;\">    1.52924 </td><td style=\"text-align: right;\">0.157688   </td><td style=\"text-align: right;\">  0.702282</td><td style=\"text-align: right;\">    0.00249389</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.6584</td><td style=\"text-align: right;\">         0.70359 </td><td style=\"text-align: right;\">             0.466667</td><td style=\"text-align: right;\">       0.672988</td></tr>\n",
       "<tr><td>train_dishs_e39fbbc4</td><td>TERMINATED</td><td>172.18.58.174:436702</td><td style=\"text-align: right;\">            0.711422</td><td style=\"text-align: right;\">    0.589434</td><td style=\"text-align: right;\">0.00760068 </td><td style=\"text-align: right;\">  0.182708</td><td style=\"text-align: right;\">    0.00631247</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.9453</td><td style=\"text-align: right;\">         0.604478</td><td style=\"text-align: right;\">             0.633333</td><td style=\"text-align: right;\">       0.690199</td></tr>\n",
       "<tr><td>train_dishs_8eb23f64</td><td>TERMINATED</td><td>172.18.58.174:439718</td><td style=\"text-align: right;\">            0.841656</td><td style=\"text-align: right;\">    0.44269 </td><td style=\"text-align: right;\">0.0739625  </td><td style=\"text-align: right;\">  0.740839</td><td style=\"text-align: right;\">    0.0165443 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.0778</td><td style=\"text-align: right;\">         0.49499 </td><td style=\"text-align: right;\">             0.733333</td><td style=\"text-align: right;\">       0.512199</td></tr>\n",
       "<tr><td>train_dishs_93edbb20</td><td>TERMINATED</td><td>172.18.58.174:442717</td><td style=\"text-align: right;\">            0.623628</td><td style=\"text-align: right;\">    1.06023 </td><td style=\"text-align: right;\">0.000270502</td><td style=\"text-align: right;\">  0.860183</td><td style=\"text-align: right;\">    0.0620193 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.8918</td><td style=\"text-align: right;\">         0.721139</td><td style=\"text-align: right;\">             0.333333</td><td style=\"text-align: right;\">       0.631432</td></tr>\n",
       "<tr><td>train_dishs_20dac73e</td><td>TERMINATED</td><td>172.18.58.174:445717</td><td style=\"text-align: right;\">            0.630205</td><td style=\"text-align: right;\">    3.2365  </td><td style=\"text-align: right;\">0.00959503 </td><td style=\"text-align: right;\">  0.899774</td><td style=\"text-align: right;\">    0.0397306 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.6715</td><td style=\"text-align: right;\">         0.424696</td><td style=\"text-align: right;\">             0.8     </td><td style=\"text-align: right;\">       0.401735</td></tr>\n",
       "<tr><td>train_dishs_5f3db80e</td><td>TERMINATED</td><td>172.18.58.174:448731</td><td style=\"text-align: right;\">            0.676087</td><td style=\"text-align: right;\">    0.350299</td><td style=\"text-align: right;\">0.0449037  </td><td style=\"text-align: right;\">  0.681983</td><td style=\"text-align: right;\">    0.105584  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.8104</td><td style=\"text-align: right;\">         0.6825  </td><td style=\"text-align: right;\">             0.533333</td><td style=\"text-align: right;\">       0.682749</td></tr>\n",
       "<tr><td>train_dishs_a16e0479</td><td>TERMINATED</td><td>172.18.58.174:451749</td><td style=\"text-align: right;\">            0.679183</td><td style=\"text-align: right;\">    2.4608  </td><td style=\"text-align: right;\">0.0104276  </td><td style=\"text-align: right;\">  0.875567</td><td style=\"text-align: right;\">    0.045382  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.3593</td><td style=\"text-align: right;\">         0.480974</td><td style=\"text-align: right;\">             0.766667</td><td style=\"text-align: right;\">       0.435572</td></tr>\n",
       "<tr><td>train_dishs_93d0aa41</td><td>TERMINATED</td><td>172.18.58.174:454758</td><td style=\"text-align: right;\">            0.503395</td><td style=\"text-align: right;\">    2.04064 </td><td style=\"text-align: right;\">0.0323761  </td><td style=\"text-align: right;\">  0.674457</td><td style=\"text-align: right;\">    0.0384823 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.7199</td><td style=\"text-align: right;\">         0.215986</td><td style=\"text-align: right;\">             0.966667</td><td style=\"text-align: right;\">       0.550515</td></tr>\n",
       "<tr><td>train_dishs_bc5ee21a</td><td>TERMINATED</td><td>172.18.58.174:457773</td><td style=\"text-align: right;\">            0.669008</td><td style=\"text-align: right;\">    2.58884 </td><td style=\"text-align: right;\">0.0104795  </td><td style=\"text-align: right;\">  0.837163</td><td style=\"text-align: right;\">    0.0598111 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.6457</td><td style=\"text-align: right;\">         0.457458</td><td style=\"text-align: right;\">             0.766667</td><td style=\"text-align: right;\">       0.823519</td></tr>\n",
       "<tr><td>train_dishs_92c7b003</td><td>TERMINATED</td><td>172.18.58.174:460792</td><td style=\"text-align: right;\">            0.664432</td><td style=\"text-align: right;\">    3.60258 </td><td style=\"text-align: right;\">0.0177294  </td><td style=\"text-align: right;\">  0.893937</td><td style=\"text-align: right;\">    0.0416662 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         20.8043</td><td style=\"text-align: right;\">         0.782722</td><td style=\"text-align: right;\">             0.566667</td><td style=\"text-align: right;\">       0.617647</td></tr>\n",
       "<tr><td>train_dishs_4addd42c</td><td>TERMINATED</td><td>172.18.58.174:463814</td><td style=\"text-align: right;\">            0.610533</td><td style=\"text-align: right;\">    2.67806 </td><td style=\"text-align: right;\">0.00777273 </td><td style=\"text-align: right;\">  0.633304</td><td style=\"text-align: right;\">    0.0107055 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         21.0921</td><td style=\"text-align: right;\">         0.379689</td><td style=\"text-align: right;\">             0.833333</td><td style=\"text-align: right;\">       0.565845</td></tr>\n",
       "<tr><td>train_dishs_cd806219</td><td>TERMINATED</td><td>172.18.58.174:466840</td><td style=\"text-align: right;\">            0.569624</td><td style=\"text-align: right;\">    3.51133 </td><td style=\"text-align: right;\">0.00137137 </td><td style=\"text-align: right;\">  0.101767</td><td style=\"text-align: right;\">    0.0870619 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         20.2021</td><td style=\"text-align: right;\">         0.666195</td><td style=\"text-align: right;\">             0.566667</td><td style=\"text-align: right;\">       0.701072</td></tr>\n",
       "<tr><td>train_dishs_a814beb0</td><td>TERMINATED</td><td>172.18.58.174:469856</td><td style=\"text-align: right;\">            0.696326</td><td style=\"text-align: right;\">    1.98177 </td><td style=\"text-align: right;\">0.00490193 </td><td style=\"text-align: right;\">  0.888466</td><td style=\"text-align: right;\">    0.0363772 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.5883</td><td style=\"text-align: right;\">         0.627124</td><td style=\"text-align: right;\">             0.633333</td><td style=\"text-align: right;\">       0.644471</td></tr>\n",
       "<tr><td>train_dishs_39c3951a</td><td>TERMINATED</td><td>172.18.58.174:472871</td><td style=\"text-align: right;\">            0.943092</td><td style=\"text-align: right;\">    4.5856  </td><td style=\"text-align: right;\">0.000739946</td><td style=\"text-align: right;\">  0.79432 </td><td style=\"text-align: right;\">    0.0800173 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.2744</td><td style=\"text-align: right;\">         1.69197 </td><td style=\"text-align: right;\">             0.6     </td><td style=\"text-align: right;\">       0.707064</td></tr>\n",
       "<tr><td>train_dishs_4e1a0f9f</td><td>TERMINATED</td><td>172.18.58.174:475885</td><td style=\"text-align: right;\">            0.646891</td><td style=\"text-align: right;\">    4.15105 </td><td style=\"text-align: right;\">0.0159084  </td><td style=\"text-align: right;\">  0.503814</td><td style=\"text-align: right;\">    0.0227926 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.8066</td><td style=\"text-align: right;\">         0.412194</td><td style=\"text-align: right;\">             0.733333</td><td style=\"text-align: right;\">       0.487463</td></tr>\n",
       "<tr><td>train_dishs_ad379944</td><td>TERMINATED</td><td>172.18.58.174:478900</td><td style=\"text-align: right;\">            0.519896</td><td style=\"text-align: right;\">    2.84903 </td><td style=\"text-align: right;\">0.00459712 </td><td style=\"text-align: right;\">  0.626106</td><td style=\"text-align: right;\">    0.0463298 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.0656</td><td style=\"text-align: right;\">         0.415176</td><td style=\"text-align: right;\">             0.766667</td><td style=\"text-align: right;\">       0.531672</td></tr>\n",
       "<tr><td>train_dishs_447d7786</td><td>TERMINATED</td><td>172.18.58.174:481914</td><td style=\"text-align: right;\">            0.587374</td><td style=\"text-align: right;\">    3.44446 </td><td style=\"text-align: right;\">0.000869311</td><td style=\"text-align: right;\">  0.732903</td><td style=\"text-align: right;\">    0.0108796 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         20.1103</td><td style=\"text-align: right;\">         0.738486</td><td style=\"text-align: right;\">             0.533333</td><td style=\"text-align: right;\">       0.650642</td></tr>\n",
       "<tr><td>train_dishs_8068e43c</td><td>TERMINATED</td><td>172.18.58.174:484946</td><td style=\"text-align: right;\">            0.643722</td><td style=\"text-align: right;\">    2.29679 </td><td style=\"text-align: right;\">0.0220929  </td><td style=\"text-align: right;\">  0.822079</td><td style=\"text-align: right;\">    0.130213  </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         19.8337</td><td style=\"text-align: right;\">         0.396396</td><td style=\"text-align: right;\">             0.833333</td><td style=\"text-align: right;\">       0.85744 </td></tr>\n",
       "<tr><td>train_dishs_2c1d4416</td><td>TERMINATED</td><td>172.18.58.174:487970</td><td style=\"text-align: right;\">            0.759416</td><td style=\"text-align: right;\">    1.76689 </td><td style=\"text-align: right;\">0.0624154  </td><td style=\"text-align: right;\">  0.459963</td><td style=\"text-align: right;\">    0.0289622 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         26.7368</td><td style=\"text-align: right;\">         0.398182</td><td style=\"text-align: right;\">             0.866667</td><td style=\"text-align: right;\">       0.390495</td></tr>\n",
       "<tr><td>train_dishs_d3902460</td><td>TERMINATED</td><td>172.18.58.174:491036</td><td style=\"text-align: right;\">            0.698023</td><td style=\"text-align: right;\">    3.75524 </td><td style=\"text-align: right;\">0.000433166</td><td style=\"text-align: right;\">  0.892629</td><td style=\"text-align: right;\">    0.0110626 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         25.981 </td><td style=\"text-align: right;\">         0.589944</td><td style=\"text-align: right;\">             0.7     </td><td style=\"text-align: right;\">       0.705375</td></tr>\n",
       "<tr><td>train_dishs_761a5861</td><td>TERMINATED</td><td>172.18.58.174:494099</td><td style=\"text-align: right;\">            0.793088</td><td style=\"text-align: right;\">    0.118267</td><td style=\"text-align: right;\">0.0556658  </td><td style=\"text-align: right;\">  0.309898</td><td style=\"text-align: right;\">    0.0317244 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         25.938 </td><td style=\"text-align: right;\">         0.744181</td><td style=\"text-align: right;\">             0.5     </td><td style=\"text-align: right;\">       0.689196</td></tr>\n",
       "<tr><td>train_dishs_f63cdb6d</td><td>TERMINATED</td><td>172.18.58.174:497154</td><td style=\"text-align: right;\">            0.742994</td><td style=\"text-align: right;\">    1.8672  </td><td style=\"text-align: right;\">4.85884e-05</td><td style=\"text-align: right;\">  0.476776</td><td style=\"text-align: right;\">    0.00376903</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         25.9627</td><td style=\"text-align: right;\">         0.748985</td><td style=\"text-align: right;\">             0.566667</td><td style=\"text-align: right;\">       0.645468</td></tr>\n",
       "<tr><td>train_dishs_eeb485b6</td><td>TERMINATED</td><td>172.18.58.174:500216</td><td style=\"text-align: right;\">            0.808583</td><td style=\"text-align: right;\">    4.36073 </td><td style=\"text-align: right;\">0.0744087  </td><td style=\"text-align: right;\">  0.316232</td><td style=\"text-align: right;\">    0.0196285 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         26.0277</td><td style=\"text-align: right;\">         0.658359</td><td style=\"text-align: right;\">             0.6     </td><td style=\"text-align: right;\">       0.852994</td></tr>\n",
       "<tr><td>train_dishs_bd261014</td><td>TERMINATED</td><td>172.18.58.174:503288</td><td style=\"text-align: right;\">            0.89772 </td><td style=\"text-align: right;\">    3.31674 </td><td style=\"text-align: right;\">0.0256721  </td><td style=\"text-align: right;\">  0.453178</td><td style=\"text-align: right;\">    0.0121621 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         25.9112</td><td style=\"text-align: right;\">         0.789905</td><td style=\"text-align: right;\">             0.633333</td><td style=\"text-align: right;\">       0.640026</td></tr>\n",
       "<tr><td>train_dishs_47789295</td><td>TERMINATED</td><td>172.18.58.174:506350</td><td style=\"text-align: right;\">            0.759067</td><td style=\"text-align: right;\">    1.74574 </td><td style=\"text-align: right;\">0.00144122 </td><td style=\"text-align: right;\">  0.549801</td><td style=\"text-align: right;\">    0.0135834 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         26.0235</td><td style=\"text-align: right;\">         0.810222</td><td style=\"text-align: right;\">             0.366667</td><td style=\"text-align: right;\">       0.755662</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_dishs pid=487970)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/glucas11/ray_results/train_dishs_2024-06-15_13-59-23/train_dishs_2c1d4416_34_classifier_dropout=0.7594,clip_value=1.7669,lr=0.0624,momentum=0.4600,weight_decay=0.0290_2024-06-15_14-11-34/checkpoint_000000)\n",
      "2024-06-15 14:15:17,320\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/glucas11/ray_results/train_dishs_2024-06-15_13-59-23' in 0.0085s.\n",
      "2024-06-15 14:15:17,330\tINFO tune.py:1041 -- Total run time: 951.89 seconds (951.84 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -10, -1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"classifier_dropout\": hp.uniform(\"classifier_dropout\", 0.5, 0.95),\n",
    "    \"weight_decay\": hp.loguniform(\"weight_decay\", -6, -2),\n",
    "    \"clip_value\": hp.uniform(\"clip_value\", 0.1, 5.0),\n",
    "}\n",
    "\n",
    "hyperopt_search = HyperOptSearch(space, metric=\"val_mean_accuracy\", mode=\"max\")\n",
    "\n",
    "trainable_with_resources = tune.with_resources(train_dishs, {\"gpu\": 1})\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=40,\n",
    "        search_alg=hyperopt_search,\n",
    "    ),\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10 ** (-10 * np.random.rand())),\n",
    "    \"momentum\": tune.uniform(0.1, 0.9),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainable_with_resources = tune.with_resources(train_dishs, {\"gpu\": 1})\\ntuner = tune.Tuner(\\n    trainable_with_resources,\\n    tune_config=tune.TuneConfig(\\n        num_samples=20,\\n        scheduler=ASHAScheduler(metric=\"mean_accuracy\", mode=\"max\"),\\n        \\n    ),\\n    param_space=search_space,\\n)\\nresults = tuner.fit()\\n\\n# Obtain a trial dataframe from all run trials of this `tune.run` call.\\ndfs = {result.path: result.metrics_dataframe for result in results}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"trainable_with_resources = tune.with_resources(train_dishs, {\"gpu\": 1})\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_resources,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        num_samples=20,\n",
    "        scheduler=ASHAScheduler(metric=\"mean_accuracy\", mode=\"max\"),\n",
    "        \n",
    "    ),\n",
    "    param_space=search_space,\n",
    ")\n",
    "results = tuner.fit()\n",
    "\n",
    "# Obtain a trial dataframe from all run trials of this `tune.run` call.\n",
    "dfs = {result.path: result.metrics_dataframe for result in results}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_mean_loss': 0.3981822431087494,\n",
       " 'train_mean_accuracy': 0.8666666666666667,\n",
       " 'val_mean_loss': 0.3904951214790344,\n",
       " 'val_mean_accuracy': 0.8,\n",
       " 'timestamp': 1718475143,\n",
       " 'checkpoint_dir_name': 'checkpoint_000000',\n",
       " 'should_checkpoint': True,\n",
       " 'done': True,\n",
       " 'training_iteration': 20,\n",
       " 'trial_id': '2c1d4416',\n",
       " 'date': '2024-06-15_14-12-24',\n",
       " 'time_this_iter_s': 2.1849591732025146,\n",
       " 'time_total_s': 26.736804723739624,\n",
       " 'pid': 487970,\n",
       " 'hostname': 'DESKTOP-GF0BL1G',\n",
       " 'node_ip': '172.18.58.174',\n",
       " 'config': {'classifier_dropout': 0.7594161951487975,\n",
       "  'clip_value': 1.7668885218949568,\n",
       "  'lr': 0.06241539978108012,\n",
       "  'momentum': 0.4599630331725607,\n",
       "  'weight_decay': 0.028962190825140646},\n",
       " 'time_since_restore': 26.736804723739624,\n",
       " 'iterations_since_restore': 20,\n",
       " 'experiment_tag': '34_classifier_dropout=0.7594,clip_value=1.7669,lr=0.0624,momentum=0.4600,weight_decay=0.0290'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = results.get_best_result(\"val_mean_loss\", mode=\"min\")\n",
    "best_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.7594161951487975, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.7594161951487975, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = results.get_best_result(\"val_mean_loss\", mode=\"min\")\n",
    "with best_result.checkpoint.as_directory() as checkpoint_dir:\n",
    "    state_dict = torch.load(os.path.join(checkpoint_dir, \"model.pth\"))\n",
    "\n",
    "model = get_transfer_learning_model(best_result.config['classifier_dropout']).to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def to_csv(model, batch_size=10):\n",
    "    model.eval()\n",
    "    PATH_TEST = os.path.join(curr_path, \"data/test/\")\n",
    "    test_file_names = os.listdir(PATH_TEST)\n",
    "    test_file_names.sort()\n",
    "\n",
    "    submission_csv = {\n",
    "        \"id\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "\n",
    "    for file_name in test_file_names:\n",
    "        id = file_name.split(\".\")[0]\n",
    "        test_input = Image.open(os.path.join(PATH_TEST, file_name))\n",
    "        test_input = data_transforms['test'](test_input).to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred_test_label = model(test_input).max(1).indices.item()\n",
    "            pred_test_label = class_names[pred_test_label]\n",
    "        submission_csv['id'].append(id)\n",
    "        submission_csv['label'].append(pred_test_label)\n",
    "\n",
    "    submission_csv = pd.DataFrame(submission_csv).set_index(\"id\")\n",
    "    submission_csv.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- epoch: 1/100 ----------\n",
      "train: {'mean_loss': 0.8157494068145752, 'mean_accuracy': 0.5333333333333333}\n",
      "val: {'mean_loss': 0.5668608546257019, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 2/100 ----------\n",
      "train: {'mean_loss': 0.6545587778091431, 'mean_accuracy': 0.6}\n",
      "val: {'mean_loss': 0.7011714577674866, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 3/100 ----------\n",
      "train: {'mean_loss': 0.8297837972640991, 'mean_accuracy': 0.5666666666666667}\n",
      "val: {'mean_loss': 0.6197863817214966, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 4/100 ----------\n",
      "train: {'mean_loss': 0.6733068227767944, 'mean_accuracy': 0.6}\n",
      "val: {'mean_loss': 0.8567941784858704, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 5/100 ----------\n",
      "train: {'mean_loss': 0.6254743933677673, 'mean_accuracy': 0.6}\n",
      "val: {'mean_loss': 0.6771092414855957, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 6/100 ----------\n",
      "train: {'mean_loss': 0.6015492081642151, 'mean_accuracy': 0.7}\n",
      "val: {'mean_loss': 0.7042109370231628, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 7/100 ----------\n",
      "train: {'mean_loss': 0.667199969291687, 'mean_accuracy': 0.6333333333333333}\n",
      "val: {'mean_loss': 0.7217740416526794, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 8/100 ----------\n",
      "train: {'mean_loss': 0.8030171394348145, 'mean_accuracy': 0.5}\n",
      "val: {'mean_loss': 0.6552180647850037, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 9/100 ----------\n",
      "train: {'mean_loss': 0.6267447471618652, 'mean_accuracy': 0.6333333333333333}\n",
      "val: {'mean_loss': 0.6872376203536987, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 10/100 ----------\n",
      "train: {'mean_loss': 0.6090505719184875, 'mean_accuracy': 0.5666666666666667}\n",
      "val: {'mean_loss': 0.5420920252799988, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 11/100 ----------\n",
      "train: {'mean_loss': 0.5526948571205139, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5633355975151062, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 12/100 ----------\n",
      "train: {'mean_loss': 0.5082813501358032, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.5849327445030212, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 13/100 ----------\n",
      "train: {'mean_loss': 0.5148454308509827, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.6346668601036072, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 14/100 ----------\n",
      "train: {'mean_loss': 0.6106613278388977, 'mean_accuracy': 0.6666666666666666}\n",
      "val: {'mean_loss': 0.6663904190063477, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 15/100 ----------\n",
      "train: {'mean_loss': 0.5304891467094421, 'mean_accuracy': 0.6666666666666666}\n",
      "val: {'mean_loss': 0.678846001625061, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 16/100 ----------\n",
      "train: {'mean_loss': 0.49279969930648804, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.5170534253120422, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 17/100 ----------\n",
      "train: {'mean_loss': 0.5150982737541199, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.934500515460968, 'mean_accuracy': 0.5}\n",
      "---------- epoch: 18/100 ----------\n",
      "train: {'mean_loss': 0.49869975447654724, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.6402443051338196, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 19/100 ----------\n",
      "train: {'mean_loss': 0.3476245701313019, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.589677095413208, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 20/100 ----------\n",
      "train: {'mean_loss': 0.40917283296585083, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.47968369722366333, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 21/100 ----------\n",
      "train: {'mean_loss': 0.5002830028533936, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5201475024223328, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 22/100 ----------\n",
      "train: {'mean_loss': 0.5146470069885254, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.397756427526474, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 23/100 ----------\n",
      "train: {'mean_loss': 0.5323524475097656, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5229530930519104, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 24/100 ----------\n",
      "train: {'mean_loss': 0.5606945753097534, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.5571826100349426, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 25/100 ----------\n",
      "train: {'mean_loss': 0.36835023760795593, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.32560765743255615, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 26/100 ----------\n",
      "train: {'mean_loss': 0.29073405265808105, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.351591020822525, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 27/100 ----------\n",
      "train: {'mean_loss': 0.43817397952079773, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5463443398475647, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 28/100 ----------\n",
      "train: {'mean_loss': 0.3675382137298584, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.52742999792099, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 29/100 ----------\n",
      "train: {'mean_loss': 0.44078049063682556, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.748985767364502, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 30/100 ----------\n",
      "train: {'mean_loss': 0.3505956530570984, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.621224045753479, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 31/100 ----------\n",
      "train: {'mean_loss': 0.32702675461769104, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.6319427490234375, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 32/100 ----------\n",
      "train: {'mean_loss': 0.25400030612945557, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.9278813600540161, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 33/100 ----------\n",
      "train: {'mean_loss': 0.39983925223350525, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.7337296605110168, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 34/100 ----------\n",
      "train: {'mean_loss': 0.270808607339859, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5428431630134583, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 35/100 ----------\n",
      "train: {'mean_loss': 0.3393822908401489, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.5138512253761292, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 36/100 ----------\n",
      "train: {'mean_loss': 0.36916041374206543, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.48224741220474243, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 37/100 ----------\n",
      "train: {'mean_loss': 0.276445209980011, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5638130307197571, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 38/100 ----------\n",
      "train: {'mean_loss': 0.4622000753879547, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.43705281615257263, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 39/100 ----------\n",
      "train: {'mean_loss': 0.35225069522857666, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.5229447484016418, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 40/100 ----------\n",
      "train: {'mean_loss': 0.3088032603263855, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.6135511994361877, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 41/100 ----------\n",
      "train: {'mean_loss': 0.3988996148109436, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.44757500290870667, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 42/100 ----------\n",
      "train: {'mean_loss': 0.18620876967906952, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.09965108335018158, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 43/100 ----------\n",
      "train: {'mean_loss': 0.2471615970134735, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.8777470588684082, 'mean_accuracy': 0.5}\n",
      "---------- epoch: 44/100 ----------\n",
      "train: {'mean_loss': 0.3393841087818146, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5096102356910706, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 45/100 ----------\n",
      "train: {'mean_loss': 0.5302120447158813, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.3260535001754761, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 46/100 ----------\n",
      "train: {'mean_loss': 0.153019979596138, 'mean_accuracy': 1.0}\n",
      "val: {'mean_loss': 0.36816713213920593, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 47/100 ----------\n",
      "train: {'mean_loss': 0.20280778408050537, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.6957297921180725, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 48/100 ----------\n",
      "train: {'mean_loss': 0.602501392364502, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.8548914790153503, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 49/100 ----------\n",
      "train: {'mean_loss': 0.27165165543556213, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.3610256314277649, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 50/100 ----------\n",
      "train: {'mean_loss': 0.32029998302459717, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.61543208360672, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 51/100 ----------\n",
      "train: {'mean_loss': 0.2821118235588074, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5619309544563293, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 52/100 ----------\n",
      "train: {'mean_loss': 0.4202415645122528, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.2112438976764679, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 53/100 ----------\n",
      "train: {'mean_loss': 0.18513323366641998, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.569156289100647, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 54/100 ----------\n",
      "train: {'mean_loss': 0.3767054080963135, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.48969751596450806, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 55/100 ----------\n",
      "train: {'mean_loss': 0.20392870903015137, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.6635038256645203, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 56/100 ----------\n",
      "train: {'mean_loss': 0.29263004660606384, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.41156306862831116, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 57/100 ----------\n",
      "train: {'mean_loss': 0.25486719608306885, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5056336522102356, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 58/100 ----------\n",
      "train: {'mean_loss': 0.43456900119781494, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.4208155572414398, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 59/100 ----------\n",
      "train: {'mean_loss': 0.24527692794799805, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.28857582807540894, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 60/100 ----------\n",
      "train: {'mean_loss': 0.29693618416786194, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.6848024129867554, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 61/100 ----------\n",
      "train: {'mean_loss': 0.1184026300907135, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.35771963000297546, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 62/100 ----------\n",
      "train: {'mean_loss': 0.4624447226524353, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.35789433121681213, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 63/100 ----------\n",
      "train: {'mean_loss': 0.19902430474758148, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.6325888633728027, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 64/100 ----------\n",
      "train: {'mean_loss': 0.22935770452022552, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.9519938826560974, 'mean_accuracy': 0.6}\n",
      "---------- epoch: 65/100 ----------\n",
      "train: {'mean_loss': 0.4196180999279022, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.4823720157146454, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 66/100 ----------\n",
      "train: {'mean_loss': 0.5518902540206909, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.10229998826980591, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 67/100 ----------\n",
      "train: {'mean_loss': 0.2269221395254135, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.42196279764175415, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 68/100 ----------\n",
      "train: {'mean_loss': 0.23866038024425507, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.3829043507575989, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 69/100 ----------\n",
      "train: {'mean_loss': 0.12874214351177216, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.37242239713668823, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 70/100 ----------\n",
      "train: {'mean_loss': 0.1914624571800232, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 1.137717843055725, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 71/100 ----------\n",
      "train: {'mean_loss': 0.6468943357467651, 'mean_accuracy': 0.7}\n",
      "val: {'mean_loss': 0.5029745697975159, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 72/100 ----------\n",
      "train: {'mean_loss': 0.2671683728694916, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.600611686706543, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 73/100 ----------\n",
      "train: {'mean_loss': 0.28825390338897705, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.715667188167572, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 74/100 ----------\n",
      "train: {'mean_loss': 0.22889888286590576, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.18871556222438812, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 75/100 ----------\n",
      "train: {'mean_loss': 0.1851157397031784, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.3379116952419281, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 76/100 ----------\n",
      "train: {'mean_loss': 0.508331298828125, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.6475067734718323, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 77/100 ----------\n",
      "train: {'mean_loss': 0.3020841181278229, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.6786695718765259, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 78/100 ----------\n",
      "train: {'mean_loss': 0.24684759974479675, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.5625050067901611, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 79/100 ----------\n",
      "train: {'mean_loss': 0.35742348432540894, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.405501127243042, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 80/100 ----------\n",
      "train: {'mean_loss': 0.17196208238601685, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.5718386769294739, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 81/100 ----------\n",
      "train: {'mean_loss': 0.31311362981796265, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.6491380333900452, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 82/100 ----------\n",
      "train: {'mean_loss': 0.4445032775402069, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.3542652130126953, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 83/100 ----------\n",
      "train: {'mean_loss': 0.2790071666240692, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.5297986268997192, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 84/100 ----------\n",
      "train: {'mean_loss': 0.28335142135620117, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5824911594390869, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 85/100 ----------\n",
      "train: {'mean_loss': 0.3330295979976654, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5212599635124207, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 86/100 ----------\n",
      "train: {'mean_loss': 0.32468488812446594, 'mean_accuracy': 0.8}\n",
      "val: {'mean_loss': 0.49375730752944946, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 87/100 ----------\n",
      "train: {'mean_loss': 0.14125652611255646, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.5607758164405823, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 88/100 ----------\n",
      "train: {'mean_loss': 0.15431921184062958, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.11794676631689072, 'mean_accuracy': 1.0}\n",
      "---------- epoch: 89/100 ----------\n",
      "train: {'mean_loss': 0.163399338722229, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 0.9966238141059875, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 90/100 ----------\n",
      "train: {'mean_loss': 0.6512425541877747, 'mean_accuracy': 0.6666666666666666}\n",
      "val: {'mean_loss': 0.3140730857849121, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 91/100 ----------\n",
      "train: {'mean_loss': 0.20105716586112976, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.4681704044342041, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 92/100 ----------\n",
      "train: {'mean_loss': 0.12744614481925964, 'mean_accuracy': 0.9666666666666667}\n",
      "val: {'mean_loss': 0.0912974551320076, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 93/100 ----------\n",
      "train: {'mean_loss': 0.26065248250961304, 'mean_accuracy': 0.9}\n",
      "val: {'mean_loss': 1.081428050994873, 'mean_accuracy': 0.7}\n",
      "---------- epoch: 94/100 ----------\n",
      "train: {'mean_loss': 0.6768153309822083, 'mean_accuracy': 0.7333333333333333}\n",
      "val: {'mean_loss': 0.3339903950691223, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 95/100 ----------\n",
      "train: {'mean_loss': 0.19791465997695923, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.39347055554389954, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 96/100 ----------\n",
      "train: {'mean_loss': 0.14331020414829254, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.43803101778030396, 'mean_accuracy': 0.8}\n",
      "---------- epoch: 97/100 ----------\n",
      "train: {'mean_loss': 0.20223218202590942, 'mean_accuracy': 0.9333333333333333}\n",
      "val: {'mean_loss': 0.5638999342918396, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 98/100 ----------\n",
      "train: {'mean_loss': 0.4300920069217682, 'mean_accuracy': 0.7666666666666667}\n",
      "val: {'mean_loss': 0.19706980884075165, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 99/100 ----------\n",
      "train: {'mean_loss': 0.47883155941963196, 'mean_accuracy': 0.8666666666666667}\n",
      "val: {'mean_loss': 0.5779322981834412, 'mean_accuracy': 0.9}\n",
      "---------- epoch: 100/100 ----------\n",
      "train: {'mean_loss': 0.2944470942020416, 'mean_accuracy': 0.8333333333333334}\n",
      "val: {'mean_loss': 0.6595021486282349, 'mean_accuracy': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_config_train_model = train_dishs(best_result.config, max_epochs=100, tunning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = best_config_train_model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.7594161951487975, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.7594161951487975, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv(new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
