{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93ff632-03a9-4707-a1b6-09c76d197da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = 200_000\n",
    "GAMMA = 0.99\n",
    "LR = 0.00003\n",
    "\n",
    "NUM_EPISODES = 50\n",
    "SEQUENCE_LENGTH = 4\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "EPS_NUM_STEPS = 30000\n",
    "EPS_START = 0.5\n",
    "EPS_END = 0.15\n",
    "EPS_DECAY = (EPS_START - EPS_END) / (EPS_NUM_STEPS)\n",
    "\n",
    "load_model = False\n",
    "model_name = \"2023_04_14_22_32_04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01a00c5-8f61-47b8-908a-cda83305cd43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glucas\\Desktop\\test\\torch_env\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (210, 160)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "env = gym.make(\"ALE/Enduro-v5\", obs_type=\"grayscale\", render_mode='rgb_array', frameskip=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af41633-ce8e-47c7-aa49-528515accfd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "CROP_DIMS = 60, 40, 95, 95\n",
    "RESIZE = 40, 40\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def push(self, experience):\n",
    "        self.memory.append(experience)\n",
    "    \n",
    "    # for replay memory\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    # for sequence\n",
    "    def phi(self, new_state):\n",
    "        x = torch.tensor(new_state, dtype=torch.float32, device=device).unsqueeze(0)/255\n",
    "        x = torchvision.transforms.functional.crop(x, *CROP_DIMS)\n",
    "        x = torchvision.transforms.Resize(RESIZE, antialias=True)(x)\n",
    "        x = torchvision.transforms.Normalize(mean=x.mean(), std=x.std())(x)\n",
    "        self.push(x)\n",
    "        \n",
    "    def render(self):\n",
    "        if len(self.memory) < SEQUENCE_LENGTH:\n",
    "            return False, None\n",
    "\n",
    "        return True, torch.cat(tuple(self.memory), 0)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.memory.clear()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a34381e-1059-4bb7-b94f-7d8473d549bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 40, 40])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "while True:\n",
    "    env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "\"\"\"\n",
    "\n",
    "# DEBUGGING PHI\n",
    "\n",
    "sequence = Memory(SEQUENCE_LENGTH)\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "sequence.phi(state)\n",
    "rendered, x = sequence.render()\n",
    "while not(rendered):\n",
    "    sequence.phi(state)\n",
    "    rendered, x = sequence.render()\n",
    "\n",
    "print(x.shape)\n",
    "img = x.cpu().numpy().transpose((1, 2, 0))\n",
    "plt.imshow(img)\n",
    "\n",
    "def batch_images(batch):\n",
    "    grid = torchvision.utils.make_grid(batch)\n",
    "    grid = grid.cpu().numpy()\n",
    "    plt.imshow(grid.transpose([1,2,0]))\n",
    "    plt.show()\n",
    "    \n",
    "def forwad_batch_images(batch):\n",
    "    print(batch.shape)\n",
    "    batch = batch.unsqueeze(0)\n",
    "    print(batch.shape)\n",
    "    batch = batch.transpose(0,1)\n",
    "    print(batch.shape)\n",
    "    grid = torchvision.utils.make_grid(batch)\n",
    "    print(grid.shape)\n",
    "    grid = grid.cpu().detach().numpy()\n",
    "    plt.imshow(grid.transpose([1,2,0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a16ece5-4247-49a8-ad58-493a5e1140c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # 3x40x40\n",
    "        self.conv_0 = nn.Conv2d(4, 12, (4, 4), stride=1) # 3x37x37\n",
    "        self.maxpool_1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_1 = nn.Conv2d(12, 24, (3, 3), stride=1) # 4x6x6\n",
    "        self.maxpool_2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_2 = nn.Conv2d(24, 48, (2, 2), stride=1) # 4x6x6\n",
    "        self.maxpool_3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.flatten = nn.Flatten() # 4x6x6\n",
    "        self.hidden_1 = nn.Linear(432, 256)\n",
    "        self.a = nn.Linear(256, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #clear_output()\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_0(x))\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = self.maxpool_1(x)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = self.maxpool_2(x)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = self.maxpool_3(x)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = self.flatten(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.hidden_1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.a(x)\n",
    "        #print(x.shape)\n",
    "        #input()\n",
    "        return x\n",
    "    \n",
    "    def _img_forward(self, x):\n",
    "        clear_output()\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_0(x))\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.maxpool_1(x)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.maxpool_2(x)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.maxpool_3(x)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.hidden_1(x))\n",
    "        print(x.shape)\n",
    "        x = self.a(x)\n",
    "        print(x.shape)\n",
    "        time.sleep(1)\n",
    "        return x\n",
    "    \n",
    "    def q_train(self, target_net, optimizer, loss_fn, batch):\n",
    "        \n",
    "        states, actions, rewards, next_states = *zip(*batch), # let the ',' to not give syntax error\n",
    "        \n",
    "        states = torch.stack(states)\n",
    "        actions = torch.cat(actions)\n",
    "        rewards = torch.cat(rewards)\n",
    "        \n",
    "        \n",
    "        # next_states = torch.stack(next_states)\n",
    "        \n",
    "        non_final_states_mask = torch.tensor(tuple(map(lambda s: s is not None, next_states)), device=device)\n",
    "        #non_final_next_states = next_states[non_final_states_mask]\n",
    "        \n",
    "        non_final_next_states = torch.stack([s for s in next_states if s is not None])\n",
    "        \n",
    "        max_action_qvalues = torch.zeros(BATCH_SIZE, device=device)\n",
    "        with torch.no_grad():\n",
    "            max_action_qvalues[non_final_states_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "        \n",
    "        \n",
    "        # Set yj for terminal and non-terminal phij+1\n",
    "        y = rewards + GAMMA * max_action_qvalues\n",
    "        \n",
    "        qvalues = self(states).gather(1, actions)\n",
    "        loss = loss_fn(qvalues, y.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(self.parameters(), 100)\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e0f9a8-70fa-43f7-a2b3-c86cdf69fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import count\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "# Initiliaze replay memory D to capacity N\n",
    "replay_memory = Memory(D)\n",
    "sequence = Memory(SEQUENCE_LENGTH)\n",
    "\n",
    "# Initialize action-value function Q with random weights\n",
    "\n",
    "policy_net = DQN().to(device) # used to store teta\n",
    "target_net = DQN().to(device) # used to store teta-1\n",
    "\n",
    "if load_model:\n",
    "    policy_net.load_state_dict(torch.load(f'./saved_models/{model_name}/policy_net'))\n",
    "    \n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epsilon = EPS_START\n",
    "steps = 0\n",
    "episode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2f2ea-2023-45df-9da7-17d475f30d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.02076195552945137 step: 19640 epsilon: 0.2708549999995891 last_reward: tensor([0.], device='cuda:0') ep: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env.close()\n",
    "env = gym.make(\"ALE/Enduro-v5\", obs_type=\"grayscale\", render_mode='rgb_array', frameskip=4)\n",
    "\n",
    "with SummaryWriter(logdir=\"runs/\"+timestr) as writer:\n",
    "    \n",
    "    while steps < D*10 -50:\n",
    "        \n",
    "        ep_rewards = 0\n",
    "        ep_qvalues = 0\n",
    "        ep_loss = 0\n",
    "        \n",
    "        # Initialise sequence s1 = {x1} and preprocessed sequenced φ1 = φ(s1)\n",
    "        sequence.clear()\n",
    "        observation, info = env.reset()\n",
    "        sequence.phi(observation)\n",
    "\n",
    "        was_rendered = False\n",
    "        for t in count():\n",
    "            \n",
    "            if was_rendered:\n",
    "                q_value_action = policy_net(state.unsqueeze(0)).max(1)\n",
    "                ep_qvalues += abs(q_value_action[0].item())\n",
    "            \n",
    "            # With probability eps select a random action at\n",
    "            epsilon = epsilon - EPS_DECAY if epsilon > EPS_END else EPS_END\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = torch.tensor([[random.randint(0, 2)]], device=device, dtype=torch.long)\n",
    "\n",
    "            # otherwise select at = maxaQ*(phi(st), a; teta)\n",
    "            else:\n",
    "                if was_rendered:\n",
    "                    action = q_value_action[1].view(1,1)\n",
    "                else:\n",
    "                    action = torch.tensor([[random.randint(0, 2)]], device=device, dtype=torch.long)\n",
    "\n",
    "            # Execute action at in emulator and observe reward rt and image xt+1\n",
    "            observation, reward, terminated, truncated, _ = env.step(action.item() + 1)\n",
    "            \n",
    "            # reward -= 0.01\n",
    "            ep_rewards += reward\n",
    "            \n",
    "            reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "            \n",
    "            # env.render()\n",
    "\n",
    "            # Set st+1 = st, at, xt+1 and preprocess phit+1 = phi(st+1)\n",
    "            if terminated:\n",
    "                next_state = None # ordem provavelmente errada\n",
    "            else:\n",
    "                sequence.phi(observation)\n",
    "                rendered, next_state = sequence.render()  \n",
    "\n",
    "            if was_rendered:\n",
    "                replay_memory.push((state, action, reward, next_state))\n",
    "                if len(replay_memory) > BATCH_SIZE:\n",
    "                    loss = policy_net.q_train(target_net, optimizer, loss_fn, replay_memory.sample(BATCH_SIZE)).item()\n",
    "                    ep_loss += loss\n",
    "                    if t % 100 == 0:\n",
    "\n",
    "                        clear_output(wait=True)\n",
    "                        #img = state.cpu().numpy().transpose((1, 2, 0))\n",
    "                        #plt.imshow(img)\n",
    "                        #plt.show()\n",
    "                        print('loss:', loss, 'step:', steps, 'epsilon:', epsilon, 'last_reward:', reward, 'ep:', episode)\n",
    "                        \n",
    "                        writer.add_scalar(\"Loss\", ep_loss, steps)\n",
    "                        writer.add_scalar(\"Reward\", ep_rewards, steps)\n",
    "                        writer.add_scalar(\"Qvalue\", ep_qvalues, steps)\n",
    "                        writer.flush()\n",
    "                        ep_rewards = 0\n",
    "                        ep_qvalues = 0\n",
    "                        ep_loss = 0\n",
    "                        \n",
    "                    if t % 2000 == 0:\n",
    "                        target_net.load_state_dict(policy_net.state_dict())\n",
    "                        \n",
    "            was_rendered = rendered\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            if terminated or truncated or steps > D*10-50:\n",
    "                break\n",
    "        \"\"\"\n",
    "        writer.add_scalar(\"Loss\", ep_loss / t, episode)\n",
    "        writer.add_scalar(\"Reward\", ep_rewards / t, episode)\n",
    "        writer.add_scalar(\"Qvalue\", ep_qvalues / t, episode)\n",
    "        \"\"\"\n",
    "        episode += 1\n",
    "        # writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a10da4-8eb9-4279-9a6a-cdf5d1ef58b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_model_dir = './saved_models'\n",
    "\n",
    "if not os.path.exists(f'{save_model_dir}'):\n",
    "    os.mkdir(f'{save_model_dir}')\n",
    "if not os.path.exists(f'{save_model_dir}/{timestr}'):\n",
    "    os.mkdir(f'{save_model_dir}/{timestr}')\n",
    "\n",
    "torch.save(policy_net.state_dict(), f'{save_model_dir}/{timestr}/policy_net')\n",
    "torch.save(target_net.state_dict(), f'{save_model_dir}/{timestr}/target_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95858924-c92d-4563-9a4a-1ee652b4070e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "env = gym.make(\"ALE/Enduro-v5\", obs_type=\"grayscale\", render_mode='human', frameskip=4)\n",
    "\n",
    "while True:\n",
    "        sequence.clear()\n",
    "        observation, info = env.reset()\n",
    "        sequence.phi(observation)\n",
    "        env.render()\n",
    "        was_rendered = False\n",
    "        for t in count():\n",
    "            \n",
    "            if was_rendered:\n",
    "                q_value_action = policy_net(state.unsqueeze(0)).max(1)\n",
    "                action = q_value_action[1].view(1,1)\n",
    "            else:\n",
    "                action = torch.tensor([[random.randint(0,2)]], device=device, dtype=torch.long)\n",
    "                \n",
    "            # Execute action at in emulator and observe reward rt and image xt+1\n",
    "            observation, reward, terminated, truncated, _ = env.step(action.item()+1)\n",
    "            env.render()\n",
    "            if terminated:\n",
    "                next_state = None # ordem provavelmente errada\n",
    "            else:\n",
    "                sequence.phi(observation)\n",
    "                rendered, next_state = sequence.render()  \n",
    "\n",
    "            was_rendered = rendered\n",
    "            \n",
    "            state = next_state\n",
    "            if terminated or truncated:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761bd06-1372-43cb-9939-358b79ce5b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
