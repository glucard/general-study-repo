{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93ff632-03a9-4707-a1b6-09c76d197da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = 200_000\n",
    "GAMMA = 0.99\n",
    "LR = 0.00001\n",
    "\n",
    "NUM_EPISODES = 50\n",
    "SEQUENCE_LENGTH = 32\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "EPS_NUM_STEPS = 1000\n",
    "EPS_START = 0.99\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = (EPS_START - EPS_END) / (EPS_NUM_STEPS)\n",
    "\n",
    "load_model = True\n",
    "model_name = \"2023_04_17_06_38_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01a00c5-8f61-47b8-908a-cda83305cd43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glucas\\Desktop\\test\\torch_env\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (210, 160)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "env = gym.make(\"ALE/Enduro-v5\", obs_type=\"grayscale\", render_mode='rgb_array', frameskip=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af41633-ce8e-47c7-aa49-528515accfd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from itertools import islice\n",
    "import random\n",
    "\n",
    "CROP_DIMS = 60, 40, 95, 95\n",
    "RESIZE = 40, 40\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def push(self, experience):\n",
    "        self.memory.append(experience)\n",
    "    \n",
    "    # for replay memory\n",
    "    def sample(self, batch_size): # maybe separate by episode to avoid sequence where final_state -> start_state\n",
    "        rand_range = random.randint(SEQUENCE_LENGTH, len(self.memory))\n",
    "        return list(islice(self.memory, rand_range - SEQUENCE_LENGTH, rand_range))\n",
    "    \n",
    "    # for sequence\n",
    "        \n",
    "    def render(self):\n",
    "        if len(self.memory) < SEQUENCE_LENGTH:\n",
    "            return False, None\n",
    "\n",
    "        return True, torch.cat(tuple(self.memory), 0)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.memory.clear()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b60a87-38af-4709-82aa-ad7bb9eff089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(observation):\n",
    "    x = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)/255\n",
    "    x = torchvision.transforms.functional.crop(x, *CROP_DIMS)\n",
    "    x = torchvision.transforms.Resize(RESIZE, antialias=True)(x)\n",
    "    x = torchvision.transforms.Normalize(mean=x.mean(), std=x.std())(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a34381e-1059-4bb7-b94f-7d8473d549bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x, _ = env.reset()\n",
    "\n",
    "x = phi(x).cpu().numpy().transpose([1,2,0])\n",
    "plt.imshow(x)\n",
    "plt.show()\n",
    "\n",
    "def batch_images(batch):\n",
    "    grid = torchvision.utils.make_grid(batch)\n",
    "    grid = grid.cpu().numpy()\n",
    "    plt.imshow(grid.transpose([1,2,0]))\n",
    "    plt.show()\n",
    "    \n",
    "def forwad_batch_images(batch):\n",
    "    batch = batch.unsqueeze(0)\n",
    "    batch = batch.transpose(0,1)\n",
    "    grid = torchvision.utils.make_grid(batch)\n",
    "    grid = grid.cpu().detach().numpy()\n",
    "    plt.imshow(grid.transpose([1,2,0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a16ece5-4247-49a8-ad58-493a5e1140c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # 3x40x40\n",
    "        self.conv_0 = nn.Conv2d(1, 12, (4, 4), stride=1) # 3x37x37\n",
    "        self.maxpool_1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_1 = nn.Conv2d(12, 24, (3, 3), stride=1) # 4x6x6\n",
    "        self.maxpool_2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv_2 = nn.Conv2d(24, 48, (2, 2), stride=1) # 4x6x6\n",
    "        self.maxpool_3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.flatten = nn.Flatten() # 4x6x6\n",
    "        \n",
    "        self.lstm = nn.LSTM(432, 256, 1)\n",
    "        self.a = nn.Linear(256, env.action_space.n)\n",
    "        \n",
    "    def forward(self, x, hn, cn):\n",
    "        #clear_output()\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_0(x))\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = self.maxpool_1(x)\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = self.maxpool_2(x)\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        x = self.maxpool_3(x)\n",
    "        #print(x.shape)\n",
    "        #forwad_batch_images(x[0])\n",
    "        #x = self.flatten(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        #print(x.shape)\n",
    "        x, (hn, cn) = self.lstm(x, (hn, cn))\n",
    "        #print(x.shape)\n",
    "        x = self.a(x)\n",
    "        #print(x.shape)\n",
    "        #input()\n",
    "        return x, hn, cn\n",
    "    \n",
    "    def _img_forward(self, x, hn, cn):\n",
    "        clear_output()\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_0(x))\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.maxpool_1(x)\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.maxpool_2(x)\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.maxpool_3(x)\n",
    "        print(x.shape)\n",
    "        forwad_batch_images(x[0])\n",
    "        x = self.flatten(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        print(x.shape)\n",
    "        x, (hn, cn) = self.lstm(x, (hn, cn))\n",
    "        print(x.shape)\n",
    "        x = self.a(x)\n",
    "        print(x.shape)\n",
    "        input()\n",
    "        return x, hn, cn\n",
    "    \n",
    "    def q_train(self, target_net, optimizer, loss_fn, sequence):\n",
    "        \n",
    "        states, actions, rewards, next_states = *zip(*sequence), # let the ',' to not give syntax error\n",
    "        \n",
    "        states = torch.stack(states)\n",
    "        actions = torch.cat(actions)\n",
    "        rewards = torch.cat(rewards)\n",
    "        \n",
    "        # next_states = torch.stack(next_states)\n",
    "        \n",
    "        non_final_states_mask = torch.tensor(tuple(map(lambda s: s is not None, next_states)), device=device)\n",
    "        #non_final_next_states = next_states[non_final_states_mask]\n",
    "        \n",
    "        non_final_next_states = torch.stack([s for s in next_states if s is not None])\n",
    "        \n",
    "        max_action_qvalues = torch.zeros(SEQUENCE_LENGTH, device=device)\n",
    "        with torch.no_grad():\n",
    "            hn = torch.zeros(1, 256, dtype=torch.float32, device=device)\n",
    "            cn = torch.zeros(1, 256, dtype=torch.float32, device=device)\n",
    "            output = target_net(non_final_next_states, hn, cn)\n",
    "            y, hn, cn = output\n",
    "            max_action_qvalues[non_final_states_mask] = y.max(1)[0]        \n",
    "        \n",
    "        # Set yj for terminal and non-terminal phij+1\n",
    "        y = rewards + GAMMA * max_action_qvalues\n",
    "        \n",
    "        \n",
    "        hn = torch.zeros(1, 256, dtype=torch.float32, device=device, requires_grad=True)\n",
    "        cn = torch.zeros(1, 256, dtype=torch.float32, device=device, requires_grad=True)\n",
    "        qvalues, hn, cn = self(states, hn, cn)\n",
    "        qvalues = qvalues.gather(1, actions)\n",
    "                                 \n",
    "        loss = loss_fn(qvalues, y.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(self.parameters(), 100)\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e0f9a8-70fa-43f7-a2b3-c86cdf69fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import count\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "# Initiliaze replay memory D to capacity N\n",
    "replay_memory = Memory(D)\n",
    "\n",
    "# Initialize action-value function Q with random weights\n",
    "\n",
    "policy_net = DQN().to(device) # used to store teta\n",
    "target_net = DQN().to(device) # used to store teta-1\n",
    "\n",
    "if load_model:\n",
    "    policy_net.load_state_dict(torch.load(f'./saved_models/{model_name}/policy_net'))\n",
    "    \n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epsilon = EPS_START\n",
    "steps = 0\n",
    "episode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af36b3-0351-44b5-8761-b3f238914283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.029920900240540504 step: 15612 epsilon: 0.05 last_reward: tensor([0.], device='cuda:0') ep: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env.close()\n",
    "env = gym.make(\"ALE/Enduro-v5\", obs_type=\"grayscale\", render_mode='rgb_array', frameskip=4)\n",
    "with SummaryWriter(logdir=\"runs/\"+timestr) as writer:\n",
    "    \n",
    "    while steps < D*10 -50:\n",
    "        \n",
    "        ep_rewards = 0\n",
    "        ep_qvalues = 0\n",
    "        ep_loss = 0\n",
    "        \n",
    "        # Initialise sequence s1 = {x1} and preprocessed sequenced φ1 = φ(s1)\n",
    "        observation, info = env.reset()\n",
    "        state = phi(observation)\n",
    "        \n",
    "        hn = torch.zeros(1, 256, dtype=torch.float32, device=device)\n",
    "        cn = torch.zeros(1, 256, dtype=torch.float32, device=device)\n",
    "        for t in count():\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                q_value_action, hn, cn = policy_net(state.unsqueeze(0), hn, cn)\n",
    "                q_value_action = q_value_action.max(1)\n",
    "                \n",
    "            ep_qvalues += abs(q_value_action[0].item())\n",
    "            \n",
    "            # With probability eps select a random action at\n",
    "            epsilon = epsilon - EPS_DECAY if epsilon > EPS_END else EPS_END\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "            # otherwise select at = maxaQ*(phi(st), a; teta)\n",
    "            else:\n",
    "                action = q_value_action[1].view(1,1)\n",
    "\n",
    "            # Execute action at in emulator and observe reward rt and image xt+1\n",
    "            observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "            \n",
    "            # reward -= 0.01\n",
    "            ep_rewards += reward\n",
    "            \n",
    "            reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "            \n",
    "            # env.render()\n",
    "\n",
    "            # Set st+1 = st, at, xt+1 and preprocess phit+1 = phi(st+1)\n",
    "            if terminated:\n",
    "                next_state = None # ordem provavelmente errada\n",
    "            else:\n",
    "                next_state = phi(observation)\n",
    "\n",
    "            replay_memory.push((state, action, reward, next_state))\n",
    "            \n",
    "            if len(replay_memory) > SEQUENCE_LENGTH:\n",
    "                loss = policy_net.q_train(target_net, optimizer, loss_fn, replay_memory.sample(SEQUENCE_LENGTH)).item()\n",
    "                ep_loss += loss\n",
    "                if t % 100 == 0:\n",
    "\n",
    "                    clear_output(wait=True)\n",
    "                    #img = state.cpu().numpy().transpose((1, 2, 0))\n",
    "                    #plt.imshow(img)\n",
    "                    #plt.show()\n",
    "                    print('loss:', loss, 'step:', steps, 'epsilon:', epsilon, 'last_reward:', reward, 'ep:', episode)\n",
    "\n",
    "                    writer.add_scalar(\"Loss\", ep_loss, steps)\n",
    "                    writer.add_scalar(\"Reward\", ep_rewards, steps)\n",
    "                    writer.add_scalar(\"Qvalue\", ep_qvalues, steps)\n",
    "                    writer.flush()\n",
    "                    ep_rewards = 0\n",
    "                    ep_qvalues = 0\n",
    "                    ep_loss = 0\n",
    "\n",
    "                if t % 1000 == 0:\n",
    "                    target_net.load_state_dict(policy_net.state_dict())\n",
    "                    \n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            if terminated or truncated or steps > D*10-50:\n",
    "                break\n",
    "        \"\"\"\n",
    "        writer.add_scalar(\"Loss\", ep_loss / t, episode)\n",
    "        writer.add_scalar(\"Reward\", ep_rewards / t, episode)\n",
    "        writer.add_scalar(\"Qvalue\", ep_qvalues / t, episode)\n",
    "        \"\"\"\n",
    "        episode += 1\n",
    "        # writer.flush()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "deb3520f-d894-4b41-8403-7e84c8f7d01e",
   "metadata": {
    "tags": []
   },
   "source": [
    "import os\n",
    "\n",
    "save_model_dir = './saved_models'\n",
    "\n",
    "if not os.path.exists(f'{save_model_dir}'):\n",
    "    os.mkdir(f'{save_model_dir}')\n",
    "if not os.path.exists(f'{save_model_dir}/{timestr}'):\n",
    "    os.mkdir(f'{save_model_dir}/{timestr}')\n",
    "\n",
    "torch.save(policy_net.state_dict(), f'{save_model_dir}/{timestr}/policy_net')\n",
    "torch.save(target_net.state_dict(), f'{save_model_dir}/{timestr}/target_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95858924-c92d-4563-9a4a-1ee652b4070e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glucas\\Desktop\\test\\torch_env\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (210, 160)\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\glucas\\Desktop\\test\\torch_env\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\glucas\\Desktop\\test\\torch_env\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "env = gym.make(\"ALE/Enduro-v5\", obs_type=\"grayscale\", render_mode='human', frameskip=4)\n",
    "\n",
    "while True:\n",
    "    \n",
    "        observation, info = env.reset()\n",
    "        state = phi(observation)\n",
    "        \n",
    "        env.render()\n",
    "        hn = torch.zeros(1, 256, dtype=torch.float32, device=device)\n",
    "        cn = torch.zeros(1, 256, dtype=torch.float32, device=device)\n",
    "        \n",
    "        for t in count():\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output, hn, cn = policy_net.forward(state.unsqueeze(0), hn, cn)\n",
    "            q_value_action = output.max(1)\n",
    "            action = q_value_action[1].view(1,1)\n",
    "                \n",
    "            # Execute action at in emulator and observe reward rt and image xt+1\n",
    "            observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "            env.render()\n",
    "            \n",
    "            state = phi(observation)\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761bd06-1372-43cb-9939-358b79ce5b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
